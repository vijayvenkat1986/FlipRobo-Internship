{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.2\n",
      "    Uninstalling urllib3-1.26.2:\n",
      "      Successfully uninstalled urllib3-1.26.2\n",
      "Successfully installed urllib3-1.25.11\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "1\n",
      "8\n",
      "11\n",
      "['Main Page']\n",
      "[\"From today's featured article\", 'Did you know\\xa0...', 'In the news', 'On this day', \"Today's featured picture\", 'Other areas of Wikipedia', \"Wikipedia's sister projects\", 'Wikipedia languages']\n",
      "['Personal tools', 'Namespaces', 'Variants', 'Views', 'More', 'Navigation', 'Contribute', 'Tools', 'Print/export', 'In other projects', 'Languages']\n"
     ]
    }
   ],
   "source": [
    "def wikipedia(url):\n",
    "    wiki_page = requests.get(url)\n",
    "    print(wiki_page)\n",
    "    bs = BeautifulSoup(wiki_page.content)\n",
    "    #Getting Header1\n",
    "    header1 = bs.find_all('h1',class_ = 'firstHeading')\n",
    "    header1_new = []\n",
    "    for i in header1:\n",
    "        header1_new.append(i.text.replace('\\n',''))\n",
    "    print(len(header1_new))\n",
    "    #Getting Header2\n",
    "    header2 = bs.find_all('h2',class_ = 'mp-h2')\n",
    "    header2_new = []\n",
    "    for i in header2:\n",
    "        header2_new.append(i.text.replace('\\n',''))\n",
    "    print(len(header2_new))\n",
    "    #Getting Header3\n",
    "    header3 = bs.find_all('h3',class_ = 'vector-menu-heading')\n",
    "    header3_new = []\n",
    "    for i in header3:\n",
    "        header3_new.append(i.text.replace('\\n',''))  \n",
    "    print(len(header3_new))\n",
    "    return(header1_new, header2_new,header3_new)\n",
    "\n",
    "h1,h2,h3 = wikipedia('https://en.wikipedia.org/wiki/Main_Page')\n",
    "print(h1)\n",
    "print(h2)\n",
    "print(h3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year_of_Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.1</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jagten</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Idi i smotri</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1952)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Movie_name Rating Year_of_Release\n",
       "0                The Shawshank Redemption    9.2          (1994)\n",
       "1                           The Godfather    9.1          (1972)\n",
       "2                  The Godfather: Part II    9.0          (1974)\n",
       "3                         The Dark Knight    9.0          (2008)\n",
       "4                            12 Angry Men    8.9          (1957)\n",
       "..                                    ...    ...             ...\n",
       "95                                 Jagten    8.3          (2012)\n",
       "96                           Idi i smotri    8.3          (1985)\n",
       "97                    Singin' in the Rain    8.3          (1952)\n",
       "98                     North by Northwest    8.3          (1959)\n",
       "99  Eternal Sunshine of the Spotless Mind    8.3          (2004)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imdb(url):\n",
    "    imdb = requests.get(url)\n",
    "    print(imdb)\n",
    "    bs = BeautifulSoup(imdb.content)\n",
    "    \n",
    "    #Getting Movie Name from IMDB\n",
    "    name = bs.find_all('td',class_ = 'titleColumn')\n",
    "    movies = []\n",
    "    for i in name:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            movies.append(j.text)\n",
    "    movies_new = movies[0:100]\n",
    "    \n",
    "    #Getting Movie Rating from IMDB\n",
    "    rating = bs.find_all('strong')\n",
    "    rating = rating[0:100]\n",
    "    ratings = []\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "    \n",
    "    #Getting Movie Release Year from IMDB\n",
    "    year=bs.find_all('span',class_=\"secondaryInfo\")\n",
    "    year = year[0:100]\n",
    "    release_year=[]   \n",
    "    for i in year:\n",
    "        release_year.append(i.get_text())\n",
    "    return(movies_new,ratings,release_year)\n",
    "    \n",
    "     \n",
    "movies,rating,release_year = imdb('https://www.imdb.com/chart/top')\n",
    "IMDB_100=pd.DataFrame({})\n",
    "IMDB_100['Movie_name']=movies\n",
    "IMDB_100['Rating']=rating\n",
    "IMDB_100['Year_of_Release']=release_year\n",
    "display(IMDB_100)\n",
    "IMDB_100.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\IMDB_Top100Movie.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year_of_Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Andaz Apna Apna</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Virumandi</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PK</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lucia</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2013)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Movie_name Rating Year_of_Release\n",
       "0            Pather Panchali    8.5          (1955)\n",
       "1                    Nayakan    8.5          (1987)\n",
       "2          Pariyerum Perumal    8.5          (2018)\n",
       "3                 Anbe Sivam    8.5          (2003)\n",
       "4                    Golmaal    8.5          (1979)\n",
       "..                       ...    ...             ...\n",
       "95           Andaz Apna Apna    8.1          (1994)\n",
       "96                 Virumandi    8.1          (2004)\n",
       "97  Uri: The Surgical Strike    8.1          (2018)\n",
       "98                        PK    8.1          (2014)\n",
       "99                     Lucia    8.1          (2013)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imdb(url):\n",
    "    imdb = requests.get(url)\n",
    "    print(imdb)\n",
    "    bs = BeautifulSoup(imdb.content)\n",
    "    \n",
    "    #Getting Movie Name from IMDB\n",
    "    name = bs.find_all('td',class_ = 'titleColumn')\n",
    "    movies = []\n",
    "    for i in name:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            movies.append(j.text)\n",
    "    movies_new = movies[0:100]\n",
    "    \n",
    "    #Getting Movie Rating from IMDB\n",
    "    rating = bs.find_all('strong')\n",
    "    rating = rating[0:100]\n",
    "    ratings = []\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "    \n",
    "    #Getting Movie Release Year from IMDB\n",
    "    year=bs.find_all('span',class_=\"secondaryInfo\")\n",
    "    year = year[0:100]\n",
    "    release_year=[]   \n",
    "    for i in year:\n",
    "        release_year.append(i.get_text())\n",
    "    return(movies_new,ratings,release_year)\n",
    "    \n",
    "     \n",
    "movies,rating,release_year = imdb('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "IMDB_INDIAN_100=pd.DataFrame({})\n",
    "IMDB_INDIAN_100['Movie_name']=movies\n",
    "IMDB_INDIAN_100['Rating']=rating\n",
    "IMDB_INDIAN_100['Year_of_Release']=release_year\n",
    "display(IMDB_INDIAN_100)\n",
    "IMDB_INDIAN_100.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\IMDB_Top100IndianMovie.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "10\n",
      "[' ★ The Outlier', ' ★ Ahmed Aziz’s Epic Year', ' ★ Cultish', ' ★ The Tangleroot Palace', ' ★ Bath Haus']\n",
      "10\n",
      "['Kai Bird', 'Nina Hamza', 'Amanda Montell', 'Marjorie Liu', 'P.J. Vernon']\n",
      "10\n",
      "['Nonfiction / Biography / American History', \"Children's / Middle Grade\", 'Nonfiction / Social Science / Linguistics', 'Science Fiction & Fantasy / Fantasy / Short Stories', 'Mystery & Suspense / Thriller']\n",
      "10\n",
      "['Bird argues that Jimmy Carter’s radical foreign policy initiatives and stellar domestic legislative record make his presidency important, despite the missteps.', '', 'Amanda Montell demonstrates that we are all more susceptible to joining cultish groups than we may realize.', '', '']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>auth_name</th>\n",
       "      <th>genre_new</th>\n",
       "      <th>book_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>★ The Outlier</td>\n",
       "      <td>Kai Bird</td>\n",
       "      <td>Nonfiction / Biography / American History</td>\n",
       "      <td>Bird argues that Jimmy Carter’s radical foreig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>★ Ahmed Aziz’s Epic Year</td>\n",
       "      <td>Nina Hamza</td>\n",
       "      <td>Children's / Middle Grade</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>★ Cultish</td>\n",
       "      <td>Amanda Montell</td>\n",
       "      <td>Nonfiction / Social Science / Linguistics</td>\n",
       "      <td>Amanda Montell demonstrates that we are all mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>★ The Tangleroot Palace</td>\n",
       "      <td>Marjorie Liu</td>\n",
       "      <td>Science Fiction &amp; Fantasy / Fantasy / Short St...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>★ Bath Haus</td>\n",
       "      <td>P.J. Vernon</td>\n",
       "      <td>Mystery &amp; Suspense / Thriller</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Book_Name       auth_name  \\\n",
       "0              ★ The Outlier        Kai Bird   \n",
       "1   ★ Ahmed Aziz’s Epic Year      Nina Hamza   \n",
       "2                  ★ Cultish  Amanda Montell   \n",
       "3    ★ The Tangleroot Palace    Marjorie Liu   \n",
       "4                ★ Bath Haus     P.J. Vernon   \n",
       "\n",
       "                                           genre_new  \\\n",
       "0          Nonfiction / Biography / American History   \n",
       "1                          Children's / Middle Grade   \n",
       "2          Nonfiction / Social Science / Linguistics   \n",
       "3  Science Fiction & Fantasy / Fantasy / Short St...   \n",
       "4                      Mystery & Suspense / Thriller   \n",
       "\n",
       "                                         book_review  \n",
       "0  Bird argues that Jimmy Carter’s radical foreig...  \n",
       "1                                                     \n",
       "2  Amanda Montell demonstrates that we are all mo...  \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def books(url):\n",
    "    books = requests.get(url)\n",
    "    print(books)\n",
    "    bs = BeautifulSoup(books.content)\n",
    "    \n",
    "    #Getting 5 Book names\n",
    "    name = bs.find_all('h4',class_ = 'italic')\n",
    "    book_name = []\n",
    "    for i in name:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            book_name.append(j.text)\n",
    "    print(len(book_name))\n",
    "    book_name = book_name[5:11]\n",
    "    print(book_name)\n",
    "    \n",
    "    #Getting 5 Author names\n",
    "    auth_name = bs.find_all('p',class_ ='sans bold')\n",
    "    auth_new = []\n",
    "    for i in auth_name:\n",
    "        auth_new.append(i.text.replace('\\n',''))\n",
    "    print(len(auth_new))\n",
    "    auth_new = auth_new[5:11]\n",
    "    print(auth_new)\n",
    "    \n",
    "    #Getting 5 genre    \n",
    "    genre = bs.find_all('p',class_='genre-links hidden-phone')\n",
    "    genre_new = []\n",
    "    for i in genre:\n",
    "        genre_new.append(i.text.replace('\\n',''))\n",
    "    print(len(genre_new))\n",
    "    genre_new = genre_new[5:11]\n",
    "    print(genre_new)\n",
    "    \n",
    "    #Getting 5 book reviews\n",
    "    review = bs.find_all('p',class_='excerpt')\n",
    "    book_review  = []\n",
    "    for i in review:\n",
    "        book_review.append(i.text.replace('\\n',''))\n",
    "    print(len(book_review))\n",
    "    book_review = book_review[5:11]\n",
    "    print(book_review)\n",
    "    return(book_name,auth_new,genre_new,book_review)\n",
    "    \n",
    "     \n",
    "book_name,auth_name,genre_new,book_review = books('https://bookpage.com/reviews')\n",
    "Book_Details=pd.DataFrame({})\n",
    "Book_Details['Book_Name']=book_name\n",
    "Book_Details['auth_name']=auth_name\n",
    "Book_Details['genre_new']=genre_new\n",
    "Book_Details['book_review']=book_review\n",
    "display(Book_Details)\n",
    "Book_Details.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\Book_Details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "['New Zealand', 'Australia', 'India', 'England', 'South Africa', 'Pakistan', 'Bangladesh', 'West Indies', 'Sri Lanka', 'Afghanistan']\n",
      "['17']\n",
      "['25', '29', '27', '20', '24', '27', '27', '24', '17']\n",
      "['17', '25', '29', '27', '20', '24', '27', '27', '24', '17']\n",
      "['2,054', '2,945', '3,344', '3,100', '2,137', '2,323', '2,438', '2,222', '1,876', '1,054']\n",
      "['121', '118', '115', '115', '107', '97', '90', '82', '78', '62']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Team_Matches</th>\n",
       "      <th>Team_Points</th>\n",
       "      <th>Team_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>25</td>\n",
       "      <td>2,945</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>3,344</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,100</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>20</td>\n",
       "      <td>2,137</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>2,323</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>27</td>\n",
       "      <td>2,438</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,222</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>24</td>\n",
       "      <td>1,876</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_Name Team_Matches Team_Points Team_Rating\n",
       "0   New Zealand           17       2,054         121\n",
       "1     Australia           25       2,945         118\n",
       "2         India           29       3,344         115\n",
       "3       England           27       3,100         115\n",
       "4  South Africa           20       2,137         107\n",
       "5      Pakistan           24       2,323          97\n",
       "6    Bangladesh           27       2,438          90\n",
       "7   West Indies           27       2,222          82\n",
       "8     Sri Lanka           24       1,876          78\n",
       "9   Afghanistan           17       1,054          62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def oditeams(url):\n",
    "    teams = requests.get(url)\n",
    "    print(teams)\n",
    "    bs = BeautifulSoup(teams.content)\n",
    "    \n",
    "    #Getting 10 Team names\n",
    "    name = bs.find_all('span',class_ = 'u-hide-phablet')\n",
    "    team_name = []\n",
    "    for i in name:\n",
    "        team_name.append(i.text)\n",
    "    team_name = team_name[0:10]\n",
    "    print (team_name)    \n",
    "    \n",
    "    #Getting 10 Matches\n",
    "    match_name = bs.find_all('td',class_ = 'rankings-block__banner--matches')\n",
    "    match_new = []\n",
    "    for i in match_name:\n",
    "        match_new.append(i.text)\n",
    "    print(match_new)\n",
    "    \n",
    "    match_name = bs.find_all('td',class_ ='table-body__cell u-center-text')\n",
    "    match_new_remaining = []\n",
    "    for i in match_name:\n",
    "        match_new_remaining.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    #Deleting the additional column\n",
    "    del match_new_remaining[1:40:2]\n",
    "    match_new_remaining = match_new_remaining[0:9]\n",
    "    print(match_new_remaining)\n",
    "    \n",
    "    match_new = match_new + match_new_remaining\n",
    "    print (match_new)\n",
    "   \n",
    "    \n",
    "    #Getting 10 team point\n",
    "    team_point = bs.find_all('td',class_ ='rankings-block__banner--points')\n",
    "    team_point_new = []\n",
    "    for i in team_point:\n",
    "        team_point_new.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "    team_point1 = bs.find_all('td',class_ ='table-body__cell u-center-text')\n",
    "    team_point_new1 = []\n",
    "    for i in team_point1:\n",
    "        team_point_new1.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    #Deleting the additional column\n",
    "    del team_point_new1[0:40:2]\n",
    "    team_point_new1 = team_point_new1[0:9]\n",
    "    \n",
    "    team_point_final = team_point_new + team_point_new1\n",
    "    print (team_point_final)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Getting rating for teams\n",
    "    team_rating = bs.find_all('td',class_ ='rankings-block__banner--rating u-text-right')\n",
    "    team_rating_new = []\n",
    "    for i in team_rating:\n",
    "        team_rating_new.append(i.text.replace('\\n','').strip())\n",
    "    \n",
    "    team_rating1 = bs.find_all('td',class_ ='table-body__cell u-text-right rating')\n",
    "    team_rating_new1 = []\n",
    "    for i in team_rating1:\n",
    "        team_rating_new1.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    #Deleting the additional column\n",
    "    team_rating_new1 = team_rating_new1[0:9]\n",
    "    \n",
    "    team_rating_final = team_rating_new + team_rating_new1\n",
    "    print (team_rating_final)\n",
    "    return (team_name,match_new,team_point_final,team_rating_final)\n",
    "      \n",
    "        \n",
    "team_name,match_new,team_point_final,team_rating_final = oditeams('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "Team_Details=pd.DataFrame({})\n",
    "Team_Details['Team_Name']=team_name\n",
    "Team_Details['Team_Matches']=match_new\n",
    "Team_Details['Team_Points']=team_point_final\n",
    "Team_Details['Team_Rating']=team_rating_final\n",
    "display(Team_Details)\n",
    "Team_Details.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\Top10TeamDetails.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "['Babar Azam']\n",
      "['Virat Kohli', 'Rohit Sharma', 'Ross Taylor', 'Aaron Finch', 'Jonny Bairstow', 'Fakhar Zaman', 'Francois du Plessis', 'David Warner', 'Shai Hope']\n",
      "['Babar Azam', 'Virat Kohli', 'Rohit Sharma', 'Ross Taylor', 'Aaron Finch', 'Jonny Bairstow', 'Fakhar Zaman', 'Francois du Plessis', 'David Warner', 'Shai Hope']\n",
      "['PAK']\n",
      "['IND', 'IND', 'NZ', 'AUS', 'ENG', 'PAK', 'SA', 'AUS', 'WI']\n",
      "['PAK', 'IND', 'IND', 'NZ', 'AUS', 'ENG', 'PAK', 'SA', 'AUS', 'WI']\n",
      "['865']\n",
      "['857', '825', '801', '791', '785', '778', '778', '773', '773']\n",
      "['865', '857', '825', '801', '791', '785', '778', '778', '773', '773']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsman_Name</th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Batsman_Name Team_Name Rating\n",
       "0           Babar Azam       PAK    865\n",
       "1          Virat Kohli       IND    857\n",
       "2         Rohit Sharma       IND    825\n",
       "3          Ross Taylor        NZ    801\n",
       "4          Aaron Finch       AUS    791\n",
       "5       Jonny Bairstow       ENG    785\n",
       "6         Fakhar Zaman       PAK    778\n",
       "7  Francois du Plessis        SA    778\n",
       "8         David Warner       AUS    773\n",
       "9            Shai Hope        WI    773"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def odibatsmen(url):\n",
    "    teams = requests.get(url)\n",
    "    print(teams)\n",
    "    bs = BeautifulSoup(teams.content)\n",
    "    \n",
    "    #Getting 10 Player names\n",
    "    name = bs.find_all('div',class_ = 'rankings-block__banner--name-large')\n",
    "    player_name = []\n",
    "    for i in name:\n",
    "        player_name.append(i.text)\n",
    "    print (player_name)    \n",
    "    \n",
    "    names = bs.find_all('td',class_ = 'table-body__cell rankings-table__name name')\n",
    "    player_names = []\n",
    "    for i in names:\n",
    "        player_names.append(i.text.replace('\\n',''))\n",
    "    player_names = player_names[0:9]\n",
    "    print (player_names) \n",
    "    \n",
    "    player_names = player_name + player_names\n",
    "    print(player_names)\n",
    "    \n",
    "    #Getting 10 Team names\n",
    "    name = bs.find_all('div',class_ = 'rankings-block__banner--nationality')\n",
    "    team_name = []\n",
    "    for i in name:\n",
    "        team_name.append(i.text.replace('\\n','').strip())\n",
    "    print (team_name)    \n",
    "    \n",
    "    names = bs.find_all('td',class_ = 'table-body__cell nationality-logo rankings-table__team')\n",
    "    team_names = []\n",
    "    for i in names:\n",
    "        team_names.append(i.text.replace('\\n',''))\n",
    "    team_names = team_names[0:9]\n",
    "    print (team_names) \n",
    "    \n",
    "    team_names = team_name + team_names\n",
    "    print(team_names,)\n",
    "    \n",
    "    #Getting 10 Ratings\n",
    "    name = bs.find_all('div',class_ = 'rankings-block__banner--rating')\n",
    "    rating = []\n",
    "    for i in name:\n",
    "        rating.append(i.text.replace('\\n','').strip())\n",
    "    print (rating)    \n",
    "    \n",
    "    names = bs.find_all('td',class_ = 'table-body__cell rating')\n",
    "    ratings = []\n",
    "    for i in names:\n",
    "        ratings.append(i.text.replace('\\n',''))\n",
    "    ratings = ratings[0:9]\n",
    "    print (ratings) \n",
    "    \n",
    "    ratings = rating + ratings\n",
    "    print(ratings)\n",
    "    \n",
    "    return (player_names,team_names,ratings)\n",
    "    \n",
    "      \n",
    "        \n",
    "player_names,team_names,ratings = odibatsmen('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "Batsmen_Details=pd.DataFrame({})\n",
    "Batsmen_Details['Batsman_Name']=player_names\n",
    "Batsmen_Details['Team_Name'] = team_names\n",
    "Batsmen_Details['Rating']=ratings\n",
    "\n",
    "display(Batsmen_Details)\n",
    "Batsmen_Details.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\Top10Batsmen_Details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "['Trent Boult']\n",
      "['Mehedi Hasan', 'Mujeeb Ur Rahman', 'Matt Henry', 'Jasprit Bumrah', 'Kagiso Rabada', 'Chris Woakes', 'Josh Hazlewood', 'Pat Cummins', 'Mustafizur Rahman']\n",
      "['Trent Boult', 'Mehedi Hasan', 'Mujeeb Ur Rahman', 'Matt Henry', 'Jasprit Bumrah', 'Kagiso Rabada', 'Chris Woakes', 'Josh Hazlewood', 'Pat Cummins', 'Mustafizur Rahman']\n",
      "['NZ']\n",
      "['BAN', 'AFG', 'NZ', 'IND', 'SA', 'ENG', 'AUS', 'AUS', 'BAN']\n",
      "['NZ', 'BAN', 'AFG', 'NZ', 'IND', 'SA', 'ENG', 'AUS', 'AUS', 'BAN']\n",
      "['737']\n",
      "['713', '708', '691', '690', '666', '665', '660', '646', '645']\n",
      "['737', '713', '708', '691', '690', '666', '665', '660', '646', '645']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsman_Name</th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Batsman_Name Team_Name Rating\n",
       "0        Trent Boult        NZ    737\n",
       "1       Mehedi Hasan       BAN    713\n",
       "2   Mujeeb Ur Rahman       AFG    708\n",
       "3         Matt Henry        NZ    691\n",
       "4     Jasprit Bumrah       IND    690\n",
       "5      Kagiso Rabada        SA    666\n",
       "6       Chris Woakes       ENG    665\n",
       "7     Josh Hazlewood       AUS    660\n",
       "8        Pat Cummins       AUS    646\n",
       "9  Mustafizur Rahman       BAN    645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def odibowler(url):\n",
    "    teams = requests.get(url)\n",
    "    print(teams)\n",
    "    bs = BeautifulSoup(teams.content)\n",
    "    \n",
    "    #Getting 10 Player names\n",
    "    name = bs.find_all('div',class_ = 'rankings-block__banner--name-large')\n",
    "    player_name = []\n",
    "    for i in name:\n",
    "        player_name.append(i.text)\n",
    "    print (player_name)    \n",
    "    \n",
    "    names = bs.find_all('td',class_ = 'table-body__cell rankings-table__name name')\n",
    "    player_names = []\n",
    "    for i in names:\n",
    "        player_names.append(i.text.replace('\\n',''))\n",
    "    player_names = player_names[0:9]\n",
    "    print (player_names) \n",
    "    \n",
    "    player_names = player_name + player_names\n",
    "    print(player_names)\n",
    "    \n",
    "    #Getting 10 Team names\n",
    "    name = bs.find_all('div',class_ = 'rankings-block__banner--nationality')\n",
    "    team_name = []\n",
    "    for i in name:\n",
    "        team_name.append(i.text.replace('\\n','').strip())\n",
    "    print (team_name)    \n",
    "    \n",
    "    names = bs.find_all('td',class_ = 'table-body__cell nationality-logo rankings-table__team')\n",
    "    team_names = []\n",
    "    for i in names:\n",
    "        team_names.append(i.text.replace('\\n',''))\n",
    "    team_names = team_names[0:9]\n",
    "    print (team_names) \n",
    "    \n",
    "    team_names = team_name + team_names\n",
    "    print(team_names,)\n",
    "    \n",
    "    #Getting 10 Ratings\n",
    "    name = bs.find_all('div',class_ = 'rankings-block__banner--rating')\n",
    "    rating = []\n",
    "    for i in name:\n",
    "        rating.append(i.text.replace('\\n','').strip())\n",
    "    print (rating)    \n",
    "    \n",
    "    names = bs.find_all('td',class_ = 'table-body__cell rating')\n",
    "    ratings = []\n",
    "    for i in names:\n",
    "        ratings.append(i.text.replace('\\n',''))\n",
    "    ratings = ratings[0:9]\n",
    "    print (ratings) \n",
    "    \n",
    "    ratings = rating + ratings\n",
    "    print(ratings)\n",
    "    \n",
    "    return (player_names,team_names,ratings)\n",
    "    \n",
    "      \n",
    "        \n",
    "player_names,team_names,ratings = odibatsmen('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "Batsmen_Details=pd.DataFrame({})\n",
    "Batsmen_Details['Batsman_Name']=player_names\n",
    "Batsmen_Details['Team_Name'] = team_names\n",
    "Batsmen_Details['Rating']=ratings\n",
    "\n",
    "display(Batsmen_Details)\n",
    "Batsmen_Details.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\Top10Bowling_Details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "#### i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "['Australia', 'South Africa', 'England', 'India', 'New Zealand', 'West Indies', 'Pakistan', 'Bangladesh', 'Sri Lanka', 'Ireland']\n",
      "['18']\n",
      "['24', '17', '20', '21', '12', '15', '5', '11', '2']\n",
      "['18', '24', '17', '20', '21', '12', '15', '5', '11', '2']\n",
      "['2,955', '2,828', '1,993', '2,226', '1,947', '1,025', '1,101', '306', '519', '25']\n",
      "['164', '118', '117', '111', '93', '85', '73', '61', '47', '13']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Team_Matches</th>\n",
       "      <th>Team_Points</th>\n",
       "      <th>Team_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>17</td>\n",
       "      <td>1,993</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>20</td>\n",
       "      <td>2,226</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_Name Team_Matches Team_Points Team_Rating\n",
       "0     Australia           18       2,955         164\n",
       "1  South Africa           24       2,828         118\n",
       "2       England           17       1,993         117\n",
       "3         India           20       2,226         111\n",
       "4   New Zealand           21       1,947          93\n",
       "5   West Indies           12       1,025          85\n",
       "6      Pakistan           15       1,101          73\n",
       "7    Bangladesh            5         306          61\n",
       "8     Sri Lanka           11         519          47\n",
       "9       Ireland            2          25          13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def odiwomenteams(url):\n",
    "    teams = requests.get(url)\n",
    "    print(teams)\n",
    "    bs = BeautifulSoup(teams.content)\n",
    "    \n",
    "    #Getting 10 Team names\n",
    "    name = bs.find_all('span',class_ = 'u-hide-phablet')\n",
    "    team_name = []\n",
    "    for i in name:\n",
    "        team_name.append(i.text)\n",
    "    team_name = team_name[0:10]\n",
    "    print (team_name)    \n",
    "    \n",
    "    #Getting 10 Matches\n",
    "    match_name = bs.find_all('td',class_ = 'rankings-block__banner--matches')\n",
    "    match_new = []\n",
    "    for i in match_name:\n",
    "        match_new.append(i.text)\n",
    "    print(match_new)\n",
    "    \n",
    "    match_name = bs.find_all('td',class_ ='table-body__cell u-center-text')\n",
    "    match_new_remaining = []\n",
    "    for i in match_name:\n",
    "        match_new_remaining.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    #Deleting the additional column\n",
    "    del match_new_remaining[1:40:2]\n",
    "    match_new_remaining = match_new_remaining[0:9]\n",
    "    print(match_new_remaining)\n",
    "    \n",
    "    match_new = match_new + match_new_remaining\n",
    "    print (match_new)\n",
    "   \n",
    "    \n",
    "    #Getting 10 team point\n",
    "    team_point = bs.find_all('td',class_ ='rankings-block__banner--points')\n",
    "    team_point_new = []\n",
    "    for i in team_point:\n",
    "        team_point_new.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "    team_point1 = bs.find_all('td',class_ ='table-body__cell u-center-text')\n",
    "    team_point_new1 = []\n",
    "    for i in team_point1:\n",
    "        team_point_new1.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    #Deleting the additional column\n",
    "    del team_point_new1[0:40:2]\n",
    "    team_point_new1 = team_point_new1[0:9]\n",
    "    \n",
    "    team_point_final = team_point_new + team_point_new1\n",
    "    print (team_point_final)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Getting rating for teams\n",
    "    team_rating = bs.find_all('td',class_ ='rankings-block__banner--rating u-text-right')\n",
    "    team_rating_new = []\n",
    "    for i in team_rating:\n",
    "        team_rating_new.append(i.text.replace('\\n','').strip())\n",
    "    \n",
    "    team_rating1 = bs.find_all('td',class_ ='table-body__cell u-text-right rating')\n",
    "    team_rating_new1 = []\n",
    "    for i in team_rating1:\n",
    "        team_rating_new1.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    #Deleting the additional column\n",
    "    team_rating_new1 = team_rating_new1[0:9]\n",
    "    \n",
    "    team_rating_final = team_rating_new + team_rating_new1\n",
    "    print (team_rating_final)\n",
    "    return (team_name,match_new,team_point_final,team_rating_final)\n",
    "      \n",
    "        \n",
    "team_name,match_new,team_point_final,team_rating_final = oditeams('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "Team_Details=pd.DataFrame({})\n",
    "Team_Details['Team_Name']=team_name\n",
    "Team_Details['Team_Matches']=match_new\n",
    "Team_Details['Team_Points']=team_point_final\n",
    "Team_Details['Team_Rating']=team_rating_final\n",
    "display(Team_Details)\n",
    "Team_Details.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\Top10TeamDetailsWomen.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "['Tammy Beaumont']\n",
      "['Lizelle Lee', 'Alyssa Healy', 'Stafanie Taylor', 'Meg Lanning', 'Amy Satterthwaite', 'Smriti Mandhana', 'Mithali Raj', 'Natalie Sciver', 'Laura Wolvaardt']\n",
      "['Tammy Beaumont', 'Lizelle Lee', 'Alyssa Healy', 'Stafanie Taylor', 'Meg Lanning', 'Amy Satterthwaite', 'Smriti Mandhana', 'Mithali Raj', 'Natalie Sciver', 'Laura Wolvaardt']\n",
      "['ENG']\n",
      "['SA', 'AUS', 'WI', 'AUS', 'NZ', 'IND', 'IND', 'ENG', 'SA']\n",
      "['ENG', 'SA', 'AUS', 'WI', 'AUS', 'NZ', 'IND', 'IND', 'ENG', 'SA']\n",
      "['765']\n",
      "['758', '756', '746', '723', '715', '710', '709', '685', '683']\n",
      "['765', '758', '756', '746', '723', '715', '710', '709', '685', '683']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batswoman_Name</th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Batswoman_Name Team_Name Rating\n",
       "0     Tammy Beaumont       ENG    765\n",
       "1        Lizelle Lee        SA    758\n",
       "2       Alyssa Healy       AUS    756\n",
       "3    Stafanie Taylor        WI    746\n",
       "4        Meg Lanning       AUS    723\n",
       "5  Amy Satterthwaite        NZ    715\n",
       "6    Smriti Mandhana       IND    710\n",
       "7        Mithali Raj       IND    709\n",
       "8     Natalie Sciver       ENG    685\n",
       "9    Laura Wolvaardt        SA    683"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def odibatswomen(url):\n",
    "    teams = requests.get(url)\n",
    "    print(teams)\n",
    "    bs = BeautifulSoup(teams.content)\n",
    "    \n",
    "    #Getting 10 Player names\n",
    "    name = bs.find_all('div',class_ = 'rankings-block__banner--name-large')\n",
    "    player_name = []\n",
    "    for i in name:\n",
    "        player_name.append(i.text)\n",
    "    print (player_name)    \n",
    "    \n",
    "    names = bs.find_all('td',class_ = 'table-body__cell rankings-table__name name')\n",
    "    player_names = []\n",
    "    for i in names:\n",
    "        player_names.append(i.text.replace('\\n',''))\n",
    "    player_names = player_names[0:9]\n",
    "    print (player_names) \n",
    "    \n",
    "    player_names = player_name + player_names\n",
    "    print(player_names)\n",
    "    \n",
    "    #Getting 10 Team names\n",
    "    name = bs.find_all('div',class_ = 'rankings-block__banner--nationality')\n",
    "    team_name = []\n",
    "    for i in name:\n",
    "        team_name.append(i.text.replace('\\n','').strip())\n",
    "    print (team_name)    \n",
    "    \n",
    "    names = bs.find_all('td',class_ = 'table-body__cell nationality-logo rankings-table__team')\n",
    "    team_names = []\n",
    "    for i in names:\n",
    "        team_names.append(i.text.replace('\\n',''))\n",
    "    team_names = team_names[0:9]\n",
    "    print (team_names) \n",
    "    \n",
    "    team_names = team_name + team_names\n",
    "    print(team_names,)\n",
    "    \n",
    "    #Getting 10 Ratings\n",
    "    name = bs.find_all('div',class_ = 'rankings-block__banner--rating')\n",
    "    rating = []\n",
    "    for i in name:\n",
    "        rating.append(i.text.replace('\\n','').strip())\n",
    "    print (rating)    \n",
    "    \n",
    "    names = bs.find_all('td',class_ = 'table-body__cell rating')\n",
    "    ratings = []\n",
    "    for i in names:\n",
    "        ratings.append(i.text.replace('\\n',''))\n",
    "    ratings = ratings[0:9]\n",
    "    print (ratings) \n",
    "    \n",
    "    ratings = rating + ratings\n",
    "    print(ratings)\n",
    "    \n",
    "    return (player_names,team_names,ratings)\n",
    "    \n",
    "      \n",
    "        \n",
    "player_names,team_names,ratings = odibatsmen('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "Batswomen_Details=pd.DataFrame({})\n",
    "Batswomen_Details['Batswoman_Name']=player_names\n",
    "Batswomen_Details['Team_Name'] = team_names\n",
    "Batswomen_Details['Rating']=ratings\n",
    "\n",
    "display(Batswomen_Details)\n",
    "Batswomen_Details.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\Top10WomenBatswomen_Details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "['Marizanne Kapp']\n",
      "['Ellyse Perry', 'Stafanie Taylor', 'Natalie Sciver', 'Deepti Sharma', 'Jess Jonassen', 'Ashleigh Gardner', 'Dane van Niekerk', 'Sophie Devine', 'Amelia Kerr']\n",
      "['Marizanne Kapp', 'Ellyse Perry', 'Stafanie Taylor', 'Natalie Sciver', 'Deepti Sharma', 'Jess Jonassen', 'Ashleigh Gardner', 'Dane van Niekerk', 'Sophie Devine', 'Amelia Kerr']\n",
      "['SA']\n",
      "['AUS', 'WI', 'ENG', 'IND', 'AUS', 'AUS', 'SA', 'NZ', 'NZ']\n",
      "['SA', 'AUS', 'WI', 'ENG', 'IND', 'AUS', 'AUS', 'SA', 'NZ', 'NZ']\n",
      "['418']\n",
      "['418', '410', '349', '343', '307', '252', '243', '242', '236']\n",
      "['418', '418', '410', '349', '343', '307', '252', '243', '242', '236']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AllRounder_Name</th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AllRounder_Name Team_Name Rating\n",
       "0    Marizanne Kapp        SA    418\n",
       "1      Ellyse Perry       AUS    418\n",
       "2   Stafanie Taylor        WI    410\n",
       "3    Natalie Sciver       ENG    349\n",
       "4     Deepti Sharma       IND    343\n",
       "5     Jess Jonassen       AUS    307\n",
       "6  Ashleigh Gardner       AUS    252\n",
       "7  Dane van Niekerk        SA    243\n",
       "8     Sophie Devine        NZ    242\n",
       "9       Amelia Kerr        NZ    236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def odibowler(url):\n",
    "    teams = requests.get(url)\n",
    "    print(teams)\n",
    "    bs = BeautifulSoup(teams.content)\n",
    "    \n",
    "    #Getting 10 Player names\n",
    "    name = bs.find_all('div',class_ = 'rankings-block__banner--name-large')\n",
    "    player_name = []\n",
    "    for i in name:\n",
    "        player_name.append(i.text)\n",
    "    print (player_name)    \n",
    "    \n",
    "    names = bs.find_all('td',class_ = 'table-body__cell rankings-table__name name')\n",
    "    player_names = []\n",
    "    for i in names:\n",
    "        player_names.append(i.text.replace('\\n',''))\n",
    "    player_names = player_names[0:9]\n",
    "    print (player_names) \n",
    "    \n",
    "    player_names = player_name + player_names\n",
    "    print(player_names)\n",
    "    \n",
    "    #Getting 10 Team names\n",
    "    name = bs.find_all('div',class_ = 'rankings-block__banner--nationality')\n",
    "    team_name = []\n",
    "    for i in name:\n",
    "        team_name.append(i.text.replace('\\n','').strip())\n",
    "    print (team_name)    \n",
    "    \n",
    "    names = bs.find_all('td',class_ = 'table-body__cell nationality-logo rankings-table__team')\n",
    "    team_names = []\n",
    "    for i in names:\n",
    "        team_names.append(i.text.replace('\\n',''))\n",
    "    team_names = team_names[0:9]\n",
    "    print (team_names) \n",
    "    \n",
    "    team_names = team_name + team_names\n",
    "    print(team_names,)\n",
    "    \n",
    "    #Getting 10 Ratings\n",
    "    name = bs.find_all('div',class_ = 'rankings-block__banner--rating')\n",
    "    rating = []\n",
    "    for i in name:\n",
    "        rating.append(i.text.replace('\\n','').strip())\n",
    "    print (rating)    \n",
    "    \n",
    "    names = bs.find_all('td',class_ = 'table-body__cell rating')\n",
    "    ratings = []\n",
    "    for i in names:\n",
    "        ratings.append(i.text.replace('\\n',''))\n",
    "    ratings = ratings[0:9]\n",
    "    print (ratings) \n",
    "    \n",
    "    ratings = rating + ratings\n",
    "    print(ratings)\n",
    "    \n",
    "    return (player_names,team_names,ratings)\n",
    "    \n",
    "      \n",
    "        \n",
    "player_names,team_names,ratings = odibatsmen('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "Bowlwomen_Details=pd.DataFrame({})\n",
    "Bowlwomen_Details['AllRounder_Name']=player_names\n",
    "Bowlwomen_Details['Team_Name'] = team_names\n",
    "Bowlwomen_Details['Rating']=ratings\n",
    "\n",
    "display(Bowlwomen_Details)\n",
    "Bowlwomen_Details.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\Top10AllRounderWomen_Details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "['11,990', '8,799', '6,799', '10,999', '13,499', '14,499', '12,999', '11,990', '9,499', '9,499', '5,298', '6,199', '16,999', '6,799', '8,999']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Name</th>\n",
       "      <th>Image_URL</th>\n",
       "      <th>Product_Price</th>\n",
       "      <th>Average Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61IhTtJUXJ...</td>\n",
       "      <td>11,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)| 500...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71A9Vo1Bat...</td>\n",
       "      <td>8,799</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "      <td>6,799</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71X5I1cVfb...</td>\n",
       "      <td>10,999</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Galaxy M12 (Black,6GB RAM, 128GB Stora...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/714QWDxXgN...</td>\n",
       "      <td>13,499</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Redmi Note 10 (Aqua Green, 6GB RAM, 128GB Stor...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71-BcSc9rh...</td>\n",
       "      <td>14,499</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Redmi 9 Power (Mighty Black, 6GB RAM, 128GB St...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61LHaUOheh...</td>\n",
       "      <td>12,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oppo A31 (Mystery Black, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71KCwNV6Mu...</td>\n",
       "      <td>11,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Samsung Galaxy M11 (Metallic Blue, 4GB RAM, 64...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71GQUxuSpn...</td>\n",
       "      <td>9,499</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Samsung Galaxy M11 (Black, 4GB RAM, 64GB Stora...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/710jkZNub3...</td>\n",
       "      <td>9,499</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Panasonic Eluga i7 (2GB RAM, 16GB Storage, Fin...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41QsvcpKaZ...</td>\n",
       "      <td>5,298</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Product_Name  \\\n",
       "0   Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...   \n",
       "1   Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)| 500...   \n",
       "2   Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...   \n",
       "3   Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...   \n",
       "4   Samsung Galaxy M12 (Black,6GB RAM, 128GB Stora...   \n",
       "5   Redmi Note 10 (Aqua Green, 6GB RAM, 128GB Stor...   \n",
       "6   Redmi 9 Power (Mighty Black, 6GB RAM, 128GB St...   \n",
       "7   Oppo A31 (Mystery Black, 6GB RAM, 128GB Storag...   \n",
       "8   Samsung Galaxy M11 (Metallic Blue, 4GB RAM, 64...   \n",
       "9   Samsung Galaxy M11 (Black, 4GB RAM, 64GB Stora...   \n",
       "10  Panasonic Eluga i7 (2GB RAM, 16GB Storage, Fin...   \n",
       "\n",
       "                                            Image_URL Product_Price  \\\n",
       "0   https://m.media-amazon.com/images/I/61IhTtJUXJ...        11,990   \n",
       "1   https://m.media-amazon.com/images/I/71A9Vo1Bat...         8,799   \n",
       "2   https://m.media-amazon.com/images/I/71sxlhYhKW...         6,799   \n",
       "3   https://m.media-amazon.com/images/I/71X5I1cVfb...        10,999   \n",
       "4   https://m.media-amazon.com/images/I/714QWDxXgN...        13,499   \n",
       "5   https://m.media-amazon.com/images/I/71-BcSc9rh...        14,499   \n",
       "6   https://m.media-amazon.com/images/I/61LHaUOheh...        12,999   \n",
       "7   https://m.media-amazon.com/images/I/71KCwNV6Mu...        11,990   \n",
       "8   https://m.media-amazon.com/images/I/71GQUxuSpn...         9,499   \n",
       "9   https://m.media-amazon.com/images/I/710jkZNub3...         9,499   \n",
       "10  https://m.media-amazon.com/images/I/41QsvcpKaZ...         5,298   \n",
       "\n",
       "        Average Rating  \n",
       "0   4.2 out of 5 stars  \n",
       "1   4.2 out of 5 stars  \n",
       "2   4.2 out of 5 stars  \n",
       "3   4.3 out of 5 stars  \n",
       "4   4.1 out of 5 stars  \n",
       "5   4.1 out of 5 stars  \n",
       "6   4.2 out of 5 stars  \n",
       "7   4.2 out of 5 stars  \n",
       "8   4.2 out of 5 stars  \n",
       "9   4.1 out of 5 stars  \n",
       "10  3.1 out of 5 stars  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def amazonmobile(url):\n",
    "    products = requests.get(url)\n",
    "    print(products)\n",
    "    bs = BeautifulSoup(products.content)\n",
    "    \n",
    "    #Getting Product names\n",
    "    names = bs.find_all('span',class_ = 'a-size-medium a-color-base a-text-normal')\n",
    "    product_names = []\n",
    "    for i in names:\n",
    "        product_names.append(i.text)\n",
    "           \n",
    "    \n",
    "    #Getting Price of the Product\n",
    "    price = bs.find_all('span',class_ = 'a-price-whole')\n",
    "    price_details = []\n",
    "    for i in price:\n",
    "        price_details.append(i.text)\n",
    "    print(price_details)  \n",
    "     \n",
    "    #Getting Image URL\n",
    "    url = bs.find_all('img', class_ = 's-image')\n",
    "    image_url = []\n",
    "    for i in url:\n",
    "        image_url.append(i['src'])\n",
    "    \n",
    "\n",
    "    #Getting Average Rating\n",
    "    rating = bs.find_all('span',class_ = 'a-icon-alt')\n",
    "    rating_details = []\n",
    "    for i in rating:\n",
    "        rating_details.append(i.text.replace('amp;',' '))\n",
    "        \n",
    "    return (product_names,price_details,image_url,rating_details)\n",
    "        \n",
    "product_names, price_details, image_url, rating_details = amazonmobile('https://www.amazon.in/s?k=mobile+phones+under+20000&ref=nb_sb_noss')\n",
    "Product_Details = pd.DataFrame({})\n",
    "Product_Details['Product_Name'] = product_names[:11]\n",
    "Product_Details['Image_URL'] = image_url[:11]\n",
    "Product_Details['Product_Price'] = price_details[:11]\n",
    "Product_Details['Average Rating'] = rating_details[:11]\n",
    "display(Product_Details)\n",
    "Product_Details.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\AmazonProducts_Below20000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###8. Write a python program to extract information about the local weather from the National Weather Service\n",
    "website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day\n",
    "extended forecast display for the city. The data should include period, short description, temperature and\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "['Today', 'Tonight', 'Friday', 'Friday Night', 'Saturday', 'Saturday Night', 'Sunday', 'Sunday Night', 'Monday']\n",
      "['Sunny thenSunny andBreezy', 'Mostly Clear', 'Sunny thenSunny andBreezy', 'Mostly Clear', 'Sunny thenSunny andBreezy', 'Mostly Clearand Breezythen MostlyClear', 'Sunny', 'Partly Cloudy', 'Mostly Sunny']\n",
      "['High: 85 °F', 'Low: 57 °F', 'High: 76 °F', 'Low: 56 °F', 'High: 73 °F', 'Low: 56 °F', 'High: 71 °F', 'Low: 56 °F', 'High: 69 °F']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Short Description</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Long Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today</td>\n",
       "      <td>Sunny thenSunny andBreezy</td>\n",
       "      <td>High: 85 °F</td>\n",
       "      <td>Sunny, with a high near 85. Breezy, with a lig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Low: 57 °F</td>\n",
       "      <td>Mostly clear, with a low around 57. West south...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Sunny thenSunny andBreezy</td>\n",
       "      <td>High: 76 °F</td>\n",
       "      <td>Sunny, with a high near 76. Breezy, with a wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Friday Night</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Mostly clear, with a low around 56. West south...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Sunny thenSunny andBreezy</td>\n",
       "      <td>High: 73 °F</td>\n",
       "      <td>Sunny, with a high near 73. Breezy, with a wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday Night</td>\n",
       "      <td>Mostly Clearand Breezythen MostlyClear</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Mostly clear, with a low around 56. Breezy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High: 71 °F</td>\n",
       "      <td>Sunny, with a high near 71.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Period                       Short Description  Temperature  \\\n",
       "0           Today               Sunny thenSunny andBreezy  High: 85 °F   \n",
       "1         Tonight                            Mostly Clear   Low: 57 °F   \n",
       "2          Friday               Sunny thenSunny andBreezy  High: 76 °F   \n",
       "3    Friday Night                            Mostly Clear   Low: 56 °F   \n",
       "4        Saturday               Sunny thenSunny andBreezy  High: 73 °F   \n",
       "5  Saturday Night  Mostly Clearand Breezythen MostlyClear   Low: 56 °F   \n",
       "6          Sunday                                   Sunny  High: 71 °F   \n",
       "\n",
       "                                    Long Description  \n",
       "0  Sunny, with a high near 85. Breezy, with a lig...  \n",
       "1  Mostly clear, with a low around 57. West south...  \n",
       "2  Sunny, with a high near 76. Breezy, with a wes...  \n",
       "3  Mostly clear, with a low around 56. West south...  \n",
       "4  Sunny, with a high near 73. Breezy, with a wes...  \n",
       "5       Mostly clear, with a low around 56. Breezy.   \n",
       "6                        Sunny, with a high near 71.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def weather(url):\n",
    "    weather = requests.get(url)\n",
    "    print(weather)\n",
    "    bs = BeautifulSoup(weather.content)\n",
    "    \n",
    "    #Getting Period \n",
    "    period = bs.find_all('p',class_ = 'period-name')\n",
    "    period_names = []\n",
    "    for i in period:\n",
    "        period_names.append(i.text.replace('Night',' Night'))\n",
    "    print(period_names)\n",
    "            \n",
    "    #Getting Short Description\n",
    "    short = bs.find_all('p',class_ = 'short-desc')\n",
    "    short_desc = []\n",
    "    for i in short:\n",
    "        short_desc.append(i.text)\n",
    "    print(short_desc)  \n",
    "     \n",
    "    #Getting Temperature\n",
    "    temp = bs.find_all('p', class_ = 'temp')\n",
    "    temperature_details = []\n",
    "    for i in temp:\n",
    "        temperature_details.append(i.text)\n",
    "    print(temperature_details)\n",
    "    \n",
    "\n",
    "    #Getting Average Rating\n",
    "    long = bs.find_all('div',class_ = 'col-sm-10 forecast-text')\n",
    "    long_desc = []\n",
    "    for i in long:\n",
    "        long_desc.append(i.text)\n",
    "        \n",
    "    return (period_names,short_desc,temperature_details,long_desc)\n",
    "        \n",
    "period_names, short_desc, temperature_details, long_desc = weather('https://forecast.weather.gov/MapClick.php?lat=37.7749&lon=-122.4194#.YFhT9K8zZPY')\n",
    "Weather_Details = pd.DataFrame({})\n",
    "Weather_Details['Period'] = period_names[:7]\n",
    "Weather_Details['Short Description'] = short_desc[:7]\n",
    "Weather_Details['Temperature'] = temperature_details[:7]\n",
    "Weather_Details['Long Description'] = long_desc[:7]\n",
    "display(Weather_Details)\n",
    "Weather_Details.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\WeatherForecast1-7days.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title,company name, CTC, and apply date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "40 40 40 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Web Analytics Developer</td>\n",
       "      <td>DataVinci Private Limited</td>\n",
       "      <td>4.99 - 5 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Social Media Marketing Manager</td>\n",
       "      <td>The Test Tribe</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Junior Social Media Marketing Associate</td>\n",
       "      <td>Glu Studios</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Development Manager (Digital Marketin...</td>\n",
       "      <td>Graygraph Technologies LLC</td>\n",
       "      <td>3 - 4.5 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>BookLeaf Publishing</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>Ravi Ladia &amp; Co</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Research Associate</td>\n",
       "      <td>Market Vistas Consumer Insights</td>\n",
       "      <td>3 - 3.25 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Assistant Coordinator - Tender Department</td>\n",
       "      <td>Global Source Trading LLC</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Customer Relationship Manager (Publishing Cons...</td>\n",
       "      <td>Blue Rose Publishers</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Executive Assistant To Director</td>\n",
       "      <td>Best Roadways Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Learning Consultant - Sales</td>\n",
       "      <td>Geekster</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>School/Teacher Consultant</td>\n",
       "      <td>InfyBytes AI Labs Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Junior Recruiter</td>\n",
       "      <td>Radish Consultants Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Moxie.xyz</td>\n",
       "      <td>9 LPA</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Business Development Executive (Inside Sales)</td>\n",
       "      <td>GREedge</td>\n",
       "      <td>3.75 LPA</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>Fullmoon Outdoor Web Solutions</td>\n",
       "      <td>4 - 4.2 LPA</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Order Processor</td>\n",
       "      <td>InspectHOA</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>14 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Nikulsan Technologies Private Limited</td>\n",
       "      <td>3.5 - 5 LPA</td>\n",
       "      <td>14 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>IQGateway</td>\n",
       "      <td>3.6 - 10 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Reactjs Developer</td>\n",
       "      <td>Startxlabs Technologies Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>RavGins International Private Limited (Wobb.ai)</td>\n",
       "      <td>3.3 - 4 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Varenyam Placements</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Corporate Sales Associate</td>\n",
       "      <td>HealthPlix Technologies Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Inside Sales Associate</td>\n",
       "      <td>Wizklub Learning</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mobile App Developer</td>\n",
       "      <td>Fusion Engineering</td>\n",
       "      <td>4.5 - 5.25 LPA</td>\n",
       "      <td>14 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Junior MERN Stack Developer</td>\n",
       "      <td>DeepThought Edutech Ventures Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Education Innovation Manager</td>\n",
       "      <td>DeepThought Edutech Ventures Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>10 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>General Management Associate</td>\n",
       "      <td>Redwood Algorithms</td>\n",
       "      <td>4 - 5 LPA</td>\n",
       "      <td>10 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Content &amp; E-commerce Management Trainee</td>\n",
       "      <td>Blooprint Ecom Consulting</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>9 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>QuikieApps</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>9 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sales Support &amp; Operations Executive</td>\n",
       "      <td>SysCloud Technologies Private Limited</td>\n",
       "      <td>3 - 3.01 LPA</td>\n",
       "      <td>9 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Backend Developer</td>\n",
       "      <td>Medcords Healthcare Solution Private Limited</td>\n",
       "      <td>3 - 7 LPA</td>\n",
       "      <td>9 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>Bagga Infrastructure Limited</td>\n",
       "      <td>3 - 3.25 LPA</td>\n",
       "      <td>8 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Business Development (Sales) Associate</td>\n",
       "      <td>Exploring Infinities Edtech Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>8 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Corporate Sales Associate</td>\n",
       "      <td>Best Roadways Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>7 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sales Executive - Mobile/Electronics</td>\n",
       "      <td>iShopAtoZ</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>7 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Reactjs Developer</td>\n",
       "      <td>The Tech Bridge</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>7 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>SalaryBox</td>\n",
       "      <td>5 - 15 LPA</td>\n",
       "      <td>7 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PHP &amp; LARAVEL DEVELOPER</td>\n",
       "      <td>Nyx Wolves</td>\n",
       "      <td>3 - 3.05 LPA</td>\n",
       "      <td>4 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Customer Service Specialist</td>\n",
       "      <td>Wono Inc</td>\n",
       "      <td>5.2 - 6.4 LPA</td>\n",
       "      <td>3 Jul' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "0                            Web Analytics Developer    \n",
       "1              Junior Social Media Marketing Manager    \n",
       "2            Junior Social Media Marketing Associate    \n",
       "3   Business Development Manager (Digital Marketin...   \n",
       "4                     Business Development Executive    \n",
       "5                                         Accountant    \n",
       "6                                 Research Associate    \n",
       "7          Assistant Coordinator - Tender Department    \n",
       "8   Customer Relationship Manager (Publishing Cons...   \n",
       "9                    Executive Assistant To Director    \n",
       "10                       Learning Consultant - Sales    \n",
       "11                         School/Teacher Consultant    \n",
       "12                                  Junior Recruiter    \n",
       "13                                Software Developer    \n",
       "14     Business Development Executive (Inside Sales)    \n",
       "15                                     Web Developer    \n",
       "16                                   Order Processor    \n",
       "17                              Full Stack Developer    \n",
       "18                      Associate Software Developer    \n",
       "19                                 Reactjs Developer    \n",
       "20                              Full Stack Developer    \n",
       "21                    Business Development Executive    \n",
       "22                         Corporate Sales Associate    \n",
       "23                            Inside Sales Associate    \n",
       "24                              Mobile App Developer    \n",
       "25                       Junior MERN Stack Developer    \n",
       "26                      Education Innovation Manager    \n",
       "27                      General Management Associate    \n",
       "28           Content & E-commerce Management Trainee    \n",
       "29                                 Software Engineer    \n",
       "30              Sales Support & Operations Executive    \n",
       "31                                 Backend Developer    \n",
       "32                                        Accountant    \n",
       "33            Business Development (Sales) Associate    \n",
       "34                         Corporate Sales Associate    \n",
       "35              Sales Executive - Mobile/Electronics    \n",
       "36                                 Reactjs Developer    \n",
       "37                                 Software Engineer    \n",
       "38                           PHP & LARAVEL DEVELOPER    \n",
       "39                       Customer Service Specialist    \n",
       "\n",
       "                                       Company Name             CTC  \\\n",
       "0                         DataVinci Private Limited    4.99 - 5 LPA   \n",
       "1                                    The Test Tribe       3 - 4 LPA   \n",
       "2                                       Glu Studios     3 - 3.6 LPA   \n",
       "3                        Graygraph Technologies LLC     3 - 4.5 LPA   \n",
       "4                               BookLeaf Publishing     3 - 3.6 LPA   \n",
       "5                                   Ravi Ladia & Co           3 LPA   \n",
       "6                   Market Vistas Consumer Insights    3 - 3.25 LPA   \n",
       "7                         Global Source Trading LLC           3 LPA   \n",
       "8                              Blue Rose Publishers     3 - 3.5 LPA   \n",
       "9                             Best Roadways Limited           3 LPA   \n",
       "10                                         Geekster     3 - 3.5 LPA   \n",
       "11                InfyBytes AI Labs Private Limited       3 - 4 LPA   \n",
       "12               Radish Consultants Private Limited       3 - 5 LPA   \n",
       "13                                        Moxie.xyz           9 LPA   \n",
       "14                                          GREedge        3.75 LPA   \n",
       "15                   Fullmoon Outdoor Web Solutions     4 - 4.2 LPA   \n",
       "16                                       InspectHOA           3 LPA   \n",
       "17            Nikulsan Technologies Private Limited     3.5 - 5 LPA   \n",
       "18                                        IQGateway    3.6 - 10 LPA   \n",
       "19          Startxlabs Technologies Private Limited       3 - 4 LPA   \n",
       "20  RavGins International Private Limited (Wobb.ai)     3.3 - 4 LPA   \n",
       "21                              Varenyam Placements       3 - 4 LPA   \n",
       "22          HealthPlix Technologies Private Limited       3 - 4 LPA   \n",
       "23                                 Wizklub Learning       3 - 6 LPA   \n",
       "24                               Fusion Engineering  4.5 - 5.25 LPA   \n",
       "25     DeepThought Edutech Ventures Private Limited       3 - 5 LPA   \n",
       "26     DeepThought Edutech Ventures Private Limited       3 - 5 LPA   \n",
       "27                               Redwood Algorithms       4 - 5 LPA   \n",
       "28                        Blooprint Ecom Consulting           3 LPA   \n",
       "29                                       QuikieApps       3 - 4 LPA   \n",
       "30            SysCloud Technologies Private Limited    3 - 3.01 LPA   \n",
       "31     Medcords Healthcare Solution Private Limited       3 - 7 LPA   \n",
       "32                     Bagga Infrastructure Limited    3 - 3.25 LPA   \n",
       "33      Exploring Infinities Edtech Private Limited       3 - 4 LPA   \n",
       "34                            Best Roadways Limited           3 LPA   \n",
       "35                                        iShopAtoZ       3 - 6 LPA   \n",
       "36                                  The Tech Bridge           3 LPA   \n",
       "37                                        SalaryBox      5 - 15 LPA   \n",
       "38                                       Nyx Wolves    3 - 3.05 LPA   \n",
       "39                                         Wono Inc   5.2 - 6.4 LPA   \n",
       "\n",
       "    Apply Date  \n",
       "0   17 Jul' 21  \n",
       "1   17 Jul' 21  \n",
       "2   17 Jul' 21  \n",
       "3   17 Jul' 21  \n",
       "4   17 Jul' 21  \n",
       "5   16 Jul' 21  \n",
       "6   17 Jul' 21  \n",
       "7   16 Jul' 21  \n",
       "8   16 Jul' 21  \n",
       "9   17 Jul' 21  \n",
       "10  16 Jul' 21  \n",
       "11  16 Jul' 21  \n",
       "12  16 Jul' 21  \n",
       "13  15 Jul' 21  \n",
       "14  15 Jul' 21  \n",
       "15  15 Jul' 21  \n",
       "16  14 Jul' 21  \n",
       "17  14 Jul' 21  \n",
       "18  11 Jul' 21  \n",
       "19  11 Jul' 21  \n",
       "20  11 Jul' 21  \n",
       "21  11 Jul' 21  \n",
       "22  11 Jul' 21  \n",
       "23  11 Jul' 21  \n",
       "24  14 Jul' 21  \n",
       "25  15 Jul' 21  \n",
       "26  10 Jul' 21  \n",
       "27  10 Jul' 21  \n",
       "28   9 Jul' 21  \n",
       "29   9 Jul' 21  \n",
       "30   9 Jul' 21  \n",
       "31   9 Jul' 21  \n",
       "32   8 Jul' 21  \n",
       "33   8 Jul' 21  \n",
       "34   7 Jul' 21  \n",
       "35   7 Jul' 21  \n",
       "36   7 Jul' 21  \n",
       "37   7 Jul' 21  \n",
       "38   4 Jul' 21  \n",
       "39   3 Jul' 21  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def internshala(url):\n",
    "    listings = requests.get(url)\n",
    "    print(listings)\n",
    "    bs = BeautifulSoup(listings.content)\n",
    "    \n",
    "    #Getting Job Title \n",
    "    title = bs.find_all('div',class_ = 'heading_4_5 profile')\n",
    "    job_title = []\n",
    "    for i in title:\n",
    "        job_title.append(i.text.replace('\\n',''))\n",
    "    len (job_title)\n",
    "            \n",
    "    #Getting Company name\n",
    "    name = bs.find_all('div',class_ = 'heading_6 company_name')\n",
    "    comp_name = []\n",
    "    for i in name:\n",
    "        comp_name.append(i.text.replace('\\n','').strip())\n",
    "    len(comp_name)  \n",
    "     \n",
    "    #Getting CTC\n",
    "    ctc = bs.find_all('div', class_ = 'item_body')\n",
    "    CTC_Details = []\n",
    "    for i in ctc:\n",
    "        CTC_Details.append(i.text.replace('\\n','').replace('\\xa0',' ').strip())\n",
    "    CTC_Details = CTC_Details[1:120:3]\n",
    "    len(CTC_Details)\n",
    "    \n",
    "\n",
    "    #Getting Apply Date\n",
    "    date = bs.find_all('div',class_ = 'item_body')\n",
    "    apply_date = []\n",
    "    for i in date:\n",
    "        apply_date.append(i.text.replace('\\n','').replace('\\xa0','').strip())\n",
    "    apply_date = apply_date[2:120:3]\n",
    "    len(apply_date)\n",
    "    \n",
    "    print(len (job_title),len(comp_name),len(CTC_Details),len(apply_date) )\n",
    "    return (job_title,comp_name,CTC_Details,apply_date)\n",
    "        \n",
    "job_title,comp_name,CTC_Details,apply_date = internshala('https://internshala.com/fresher-jobs')\n",
    "Internshala_Freshers = pd.DataFrame({})\n",
    "Internshala_Freshers['Job Title'] = job_title\n",
    "Internshala_Freshers['Company Name'] = comp_name\n",
    "Internshala_Freshers['CTC'] = CTC_Details\n",
    "Internshala_Freshers['Apply Date'] = apply_date\n",
    "display(Internshala_Freshers)\n",
    "Internshala_Freshers.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\Internshala_Freshers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Write a python program to scrape house details from mentioned url. It should include house title, location, area, emi and price \n",
    "https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "['4+ BHK In Independent House  For Sale  In Bommasandra ', '2 BHK Apartment  For Sale  In Kb Royale In Bommasandra ', '4+ BHK For Sale  In Electronic City ', '4+ BHK Flat  For Sale  In Bommasandra Industrial Area ', '2 BHK For Sale  In Bommasandra ']\n",
      "['Independent House, 15/2,Vidyanagar, Near South End Boutique Hotel, Hosur Road', 'Kb Royale  K B Royale R S Gardeneea Hosur Rd, Vidyanagar, Bommasandra, Karnataka 560100, India', 'Standalone Building, Hosur Road, Bommasandra near Southend By TGI', 'Standalone building, Noorani Masjid NEAR  Noorani Masjid', 'Electronic City,near RK City']\n",
      "['₹80,240/Month', '₹57,314/Month', '₹1.43 Lacs/Month', '₹54,448/Month', '₹33,815/Month']\n",
      "['4,000 sqft', '1,200 sqft', '4,800 sqft', '4,300 sqft', '1,200 sqft']\n",
      "['₹1.4 Crores', '₹1 Crore', '₹2.5 Crores', '₹95 Lacs', '₹59 Lacs']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>EMI</th>\n",
       "      <th>Area</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Bomm...</td>\n",
       "      <td>Independent House, 15/2,Vidyanagar, Near South...</td>\n",
       "      <td>₹80,240/Month</td>\n",
       "      <td>4,000 sqft</td>\n",
       "      <td>₹1.4 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Kb Royale In Bom...</td>\n",
       "      <td>Kb Royale  K B Royale R S Gardeneea Hosur Rd, ...</td>\n",
       "      <td>₹57,314/Month</td>\n",
       "      <td>1,200 sqft</td>\n",
       "      <td>₹1 Crore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4+ BHK For Sale  In Electronic City</td>\n",
       "      <td>Standalone Building, Hosur Road, Bommasandra n...</td>\n",
       "      <td>₹1.43 Lacs/Month</td>\n",
       "      <td>4,800 sqft</td>\n",
       "      <td>₹2.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4+ BHK Flat  For Sale  In Bommasandra Industri...</td>\n",
       "      <td>Standalone building, Noorani Masjid NEAR  Noor...</td>\n",
       "      <td>₹54,448/Month</td>\n",
       "      <td>4,300 sqft</td>\n",
       "      <td>₹95 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 BHK For Sale  In Bommasandra</td>\n",
       "      <td>Electronic City,near RK City</td>\n",
       "      <td>₹33,815/Month</td>\n",
       "      <td>1,200 sqft</td>\n",
       "      <td>₹59 Lacs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         House Title  \\\n",
       "0  4+ BHK In Independent House  For Sale  In Bomm...   \n",
       "1  2 BHK Apartment  For Sale  In Kb Royale In Bom...   \n",
       "2               4+ BHK For Sale  In Electronic City    \n",
       "3  4+ BHK Flat  For Sale  In Bommasandra Industri...   \n",
       "4                    2 BHK For Sale  In Bommasandra    \n",
       "\n",
       "                                            Location               EMI  \\\n",
       "0  Independent House, 15/2,Vidyanagar, Near South...     ₹80,240/Month   \n",
       "1  Kb Royale  K B Royale R S Gardeneea Hosur Rd, ...     ₹57,314/Month   \n",
       "2  Standalone Building, Hosur Road, Bommasandra n...  ₹1.43 Lacs/Month   \n",
       "3  Standalone building, Noorani Masjid NEAR  Noor...     ₹54,448/Month   \n",
       "4                       Electronic City,near RK City     ₹33,815/Month   \n",
       "\n",
       "         Area        Price  \n",
       "0  4,000 sqft  ₹1.4 Crores  \n",
       "1  1,200 sqft     ₹1 Crore  \n",
       "2  4,800 sqft  ₹2.5 Crores  \n",
       "3  4,300 sqft     ₹95 Lacs  \n",
       "4  1,200 sqft     ₹59 Lacs  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def nobroker(url):\n",
    "    listings = requests.get(url)\n",
    "    print(listings)\n",
    "    bs = BeautifulSoup(listings.content)\n",
    "    \n",
    "    #Getting House Title \n",
    "    title = bs.find_all('h2',class_ = 'heading-6 font-semi-bold nb__1AShY')\n",
    "    house_title = []\n",
    "    for i in title:\n",
    "        house_title.append(i.text.replace('\\n',''))\n",
    "    len (house_title)\n",
    "    print(house_title)\n",
    "    \n",
    "             \n",
    "    #Getting Address\n",
    "    location = bs.find_all('div',class_ = 'nb__2CMjv')\n",
    "    location_details = []\n",
    "    for i in location:\n",
    "        location_details.append(i.text.replace('\\n','').replace('\\xa0',' ').strip())\n",
    "    len(location_details)  \n",
    "    print(location_details)\n",
    "     \n",
    "    #Getting EMI\n",
    "    emi = bs.find_all('div', class_ = 'font-semi-bold heading-6')\n",
    "    EMI_Details = []\n",
    "    Area_Details = []\n",
    "    Price_Details = []\n",
    "    for i in emi:\n",
    "        EMI_Details.append(i.text.replace('\\n','').replace('\\xa0',' ').strip())\n",
    "    EMI_Details = EMI_Details[1:15:3]\n",
    "    print(EMI_Details)\n",
    "    \n",
    "    #Getting Area\n",
    "    area = bs.find_all('div', class_ = 'font-semi-bold heading-6')\n",
    "    Area_Details = []\n",
    "    for i in area:\n",
    "        Area_Details.append(i.text.replace('\\n','').replace('\\xa0',' ').strip())\n",
    "    Area_Details = Area_Details[0:15:3]\n",
    "    print(Area_Details)\n",
    "    \n",
    "    #Getting Price\n",
    "    price = bs.find_all('div', class_ = 'font-semi-bold heading-6')\n",
    "    Price_Details = []\n",
    "    for i in price:\n",
    "        Price_Details.append(i.text.replace('\\n','').replace('\\xa0',' ').strip())\n",
    "    Price_Details = Price_Details[2:15:3]\n",
    "    print(Price_Details)\n",
    "    \n",
    "    return (house_title,location_details,EMI_Details,Area_Details,Price_Details)\n",
    "  \n",
    "    \n",
    "        \n",
    "#The URL mentioned in the document does not have any record so took a different URL\n",
    "house_title,location_details,EMI_Details,Area_Details,Price_Details = nobroker('https://www.nobroker.in/flats-for-sale-in-vidyanagar_bangalore')\n",
    "NoBroker_Details = pd.DataFrame({})\n",
    "NoBroker_Details['House Title'] = house_title\n",
    "NoBroker_Details['Location'] = location_details\n",
    "NoBroker_Details['EMI'] = EMI_Details\n",
    "NoBroker_Details['Area'] = Area_Details\n",
    "NoBroker_Details['Price'] = Price_Details\n",
    "display(NoBroker_Details)\n",
    "NoBroker_Details.to_csv(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\Web Scraping\\\\NoBroker_Details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
