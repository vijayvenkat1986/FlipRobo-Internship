{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”\n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\appdata\\roaming\\python\\python38\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoking chromedriver.exe file\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")\n",
    "#Opening the website\n",
    "URL = \"https://www.naukri.com/\"\n",
    "driver.get(URL)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the elements\n",
    "job_title = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "job_location=driver.find_element_by_name(\"location\")\n",
    "search_button = driver.find_element_by_class_name(\"btn\")\n",
    "#Provide the text in search job and location\n",
    "job_title.send_keys(\"Data Analyst\")\n",
    "job_location.send_keys(\"Bangalore\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"323bd6eb-4797-4692-bb1d-0c75a0028e45\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"7721c176-1e23-463c-b0a2-03519b2f84d4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"505391f9-ce04-4f0a-a7e2-03615ad750ed\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"9f35d3d6-573d-4a35-8d6d-4b269f99461e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"5857bb6b-5c5f-489c-853c-8e2ad80c101f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"8eeaadad-beaa-4f6b-a28f-e545a2a4d510\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"f3799c4d-7560-491b-8bfa-8f5c6b0ebb61\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"af1293ce-d7ab-4792-8e31-8a82a47e6165\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"f075b3d7-28d0-4eb2-b901-5671771fcf67\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"a07f331b-124e-47be-9d46-d2a0f438ae48\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"4e068695-6954-4408-b213-c0825d7de9a6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"b418e63c-20e1-4812-bcd6-69fe7bb7bd68\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"32eb0919-7a5b-4892-9a6a-5f12ec1fda91\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"04bf589a-e0b3-49fb-8630-9b23c38fc89b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"8edb815c-36fc-4c4c-bded-a287dd799c74\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"029c4b7c-4f3f-4d7f-8735-15bf8d042e26\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"60dd6172-fac9-4588-866f-47d47238f2e9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"14ed6046-f82d-4154-810b-cc72509df313\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"17c79664-2407-4737-b096-7e15a80e467f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"63d56cb4-74c7-40d5-97ac-cc19f9ee44ec\")>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business Analyst / Data Analyst - SQL Queries, Power BI & Python exp.',\n",
       " 'Immediate job openings For Partner Consultant - Sizing(Data Analyst) ',\n",
       " 'Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst (Data Stewards)//Immediate Joiners//Bangalore',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst, Component Engineering',\n",
       " 'Data Analyst(Immediate) - GSR Buz Services - Bangalore']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fetching the Job Title\n",
    "title=[]  \n",
    "\n",
    "#We need to fetch data for the first 10 job results\n",
    "for x in job_title[:10]:\n",
    "    title.append(x.text)\n",
    "\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"fec0d0db-7c84-48d7-a0aa-076daaeb3b4a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"e8ebb87f-dd26-4fc4-8c04-a6717628ef61\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"d0ff1b33-6a00-4ab9-af29-0b4610835a7b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"9704458a-dc25-480a-9034-ee1a1182c1a5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"821ccf50-b13e-466c-bbfd-396cb3146ac3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"b447134f-446e-4c7b-bc58-9f8ecd5d06bb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"1d267b08-8960-4504-9a26-32946d0e58bd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"fe4a8a4b-5a45-470f-8d6b-3f4c02f15acd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"0e178071-ea4b-44b7-9ccf-661f815069be\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"b9766297-3038-48ff-a63a-dc2094666f8f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"e469f68c-5495-419b-ace6-96bff4c488c2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"b9e5bc71-15b5-4f3e-a537-e3b5962e8263\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"6cc8f27a-b70f-4ae6-8725-dff78239cbcf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"eec476a6-d75e-42a3-ae88-493a98c65da3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"27f1ab83-141f-4728-93aa-8bd9fc5e0839\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"8d29fb0c-dba4-4dd6-9dfc-7f985e23103c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"03b57244-3cb9-4e11-88ce-5aed1641864d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"cbce0dd6-33b2-4034-86b5-8fdab2e65424\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"af2b9acd-78c8-497a-bdf5-1b48e06875e9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1dafd97c2ee2d65ba3988d854f543f47\", element=\"d8168fbb-86bd-4674-a08e-586e436b52f6\")>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fetching the job location\n",
    "job_location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chennai, Coimbatore, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(Marathahalli)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(2nd Phase JP Nagar)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Job Location Update\n",
    "jb_location=[] \n",
    "\n",
    "#Fetching data for 10 records\n",
    "for x in job_location[:10]:\n",
    "    jb_location.append(x.text)\n",
    "jb_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"31bc2071-9d81-4673-ae52-4dc52c892b06\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"581104d4-0d3e-4432-9172-c9856098f1fc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"959836a1-0729-4d04-b607-c1a49516c10b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"b177fea0-652a-44f0-ade4-22e8029dc917\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"ee14f208-236a-4334-b4e2-3ccbbe2a01fe\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"60dbaddc-e21e-4d19-b6b3-435d19a0c576\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"8e28ebda-dcd8-4780-adbf-f554d817ada7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"5d89c6b7-c0c5-470b-bdd8-6c0798820ade\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"c04a62a1-9b9e-4865-ac96-329bc5272863\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"9143a3f4-2f1b-43ba-831a-59c886086e44\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"a0b9126a-f485-4985-b214-03a277dcf51f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"4f64187e-9ab7-4edb-9132-951d4c5454e7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"5606c3e8-0b43-41d1-943a-e4d2354071df\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"83a6f649-bd37-44b8-8cc6-88b1b2948e7a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"0e401f05-d768-4202-ac4a-5e1264cdea0c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"78e42507-c422-45dd-8a65-2c54c871a821\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"7453b6d3-3f76-42c2-ba63-5d6da46cabdb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"a9bd5898-d55f-487c-acec-ad38c182a32c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"6b2ec356-1ca5-46f6-a7ea-9861a942c851\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"4d8252ee-7131-4a79-9bed-5fa8f320c23c\")>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Company name\n",
    "comp_name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "comp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AN INFRACON PRIVATE LIMITED',\n",
       " 'RANDSTAD INDIA PVT LTD',\n",
       " 'Applied Materials',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Tech Mahindra Ltd.',\n",
       " 'Microland Limited',\n",
       " 'Verizon Data Services India Pvt.Ltd',\n",
       " 'Liventus, Inc.',\n",
       " 'Rockwell Automation',\n",
       " 'GSR Business Services Private Limited.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Company\n",
    "company_name=[]  #Empty list\n",
    "\n",
    "#Loop for 10 records\n",
    "for i in comp_name[:10]:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"83f20830-e229-46f0-a0d2-8b3916cb19d2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"0ce399f5-c73a-493b-9b92-a0779fe570cf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"331fc2f5-f0cb-4f03-8d5f-9fe0ce5135d4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"fb8caa6d-9e7a-4fc6-b1cd-2bf810f4d917\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"10a52d62-e886-41c9-8146-0028aa23ab4b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"3bd71cf9-e715-4ae6-958d-42595ae024a7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"dfba976d-b5de-4fe3-804f-96ac014783a9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"43b05deb-7bfa-4d3f-a9fe-370a3268a2d5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"f86f87ee-61cf-4f02-ab43-80a6ca8ca046\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"cc03cf6e-7812-40d9-a142-1eefa27e3687\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"0d89be43-9465-4cef-9400-7c0fe47b44bf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"9c5d4d71-7ece-431c-9734-9ff4cb306e73\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"81282694-6637-40a4-a69a-d45c7c23b228\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"36e2cb2e-4ab6-4c00-ad5c-530f390e6810\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"76a4770c-9180-4d95-99fb-7307c07a969e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"f4a29211-aa88-4d74-b97e-f000781d7ceb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"28984cf1-55bf-43fe-b401-8ae89449e7f6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"de770b85-869c-410f-9c90-8ff1035d6939\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"1a19803c-fcb8-4baf-81dd-82f60fe85772\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16d91ebe6a4a9123d7249657f5e96a49\", element=\"f2b9b25b-57ed-4242-bf62-bd413d73c5f6\")>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Experience required Data\n",
    "exp_required=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "exp_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-5 Yrs',\n",
       " '1-5 Yrs',\n",
       " '7-10 Yrs',\n",
       " '2-5 Yrs',\n",
       " '5-10 Yrs',\n",
       " '3-5 Yrs',\n",
       " '3-6 Yrs',\n",
       " '5-8 Yrs',\n",
       " '2-3 Yrs',\n",
       " '3-7 Yrs']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Experience data fetching\n",
    "experience=[]  \n",
    "\n",
    "#For loop for 10 records\n",
    "for i in exp_required[:10]:\n",
    "    experience.append(i.text)\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#Length validation of all the data\n",
    "print(len(title),len(jb_location),len(company_name),len(experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Analyst / Data Analyst - SQL Queries,...</td>\n",
       "      <td>Chennai, Coimbatore, Bangalore/Bengaluru</td>\n",
       "      <td>AN INFRACON PRIVATE LIMITED</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Immediate job openings For Partner Consultant ...</td>\n",
       "      <td>Bangalore/Bengaluru(Marathahalli)</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst (Data Stewards)//Immediate Joiner...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Microland Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Verizon Data Services India Pvt.Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(2nd Phase JP Nagar)</td>\n",
       "      <td>Liventus, Inc.</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst, Component Engineering</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Rockwell Automation</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst(Immediate) - GSR Buz Services - B...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GSR Business Services Private Limited.</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0  Business Analyst / Data Analyst - SQL Queries,...   \n",
       "1  Immediate job openings For Partner Consultant ...   \n",
       "2                                       Data Analyst   \n",
       "3                                Senior Data Analyst   \n",
       "4  Data Analyst (Data Stewards)//Immediate Joiner...   \n",
       "5                                Senior Data Analyst   \n",
       "6                                Senior Data Analyst   \n",
       "7                                Senior Data Analyst   \n",
       "8                Data Analyst, Component Engineering   \n",
       "9  Data Analyst(Immediate) - GSR Buz Services - B...   \n",
       "\n",
       "                               Job_Location  \\\n",
       "0  Chennai, Coimbatore, Bangalore/Bengaluru   \n",
       "1         Bangalore/Bengaluru(Marathahalli)   \n",
       "2                       Bangalore/Bengaluru   \n",
       "3                       Bangalore/Bengaluru   \n",
       "4                       Bangalore/Bengaluru   \n",
       "5                       Bangalore/Bengaluru   \n",
       "6                       Bangalore/Bengaluru   \n",
       "7   Bangalore/Bengaluru(2nd Phase JP Nagar)   \n",
       "8                       Bangalore/Bengaluru   \n",
       "9                       Bangalore/Bengaluru   \n",
       "\n",
       "                             Company name Experience  \n",
       "0             AN INFRACON PRIVATE LIMITED    1-5 Yrs  \n",
       "1                  RANDSTAD INDIA PVT LTD    1-5 Yrs  \n",
       "2                       Applied Materials   7-10 Yrs  \n",
       "3       Flipkart Internet Private Limited    2-5 Yrs  \n",
       "4                      Tech Mahindra Ltd.   5-10 Yrs  \n",
       "5                       Microland Limited    3-5 Yrs  \n",
       "6     Verizon Data Services India Pvt.Ltd    3-6 Yrs  \n",
       "7                          Liventus, Inc.    5-8 Yrs  \n",
       "8                     Rockwell Automation    2-3 Yrs  \n",
       "9  GSR Business Services Private Limited.    3-7 Yrs  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New dataframe for the data\n",
    "job_details=pd.DataFrame({})\n",
    "job_details['Job_Title']=title\n",
    "job_details['Job_Location']=jb_location\n",
    "job_details['Company name']=company_name\n",
    "job_details['Experience']=experience\n",
    "job_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Csv file extraction\n",
    "job_details.to_csv(\"DataAnalyst_Bangalore_Naukrijobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver finally\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter\n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done\n",
    "manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoking chromedriver.exe file\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")\n",
    "#Opening the website\n",
    "URL = \"https://www.naukri.com/\"\n",
    "driver.get(URL)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the elements\n",
    "job_title = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "job_location=driver.find_element_by_name(\"location\")\n",
    "search_button = driver.find_element_by_class_name(\"btn\")\n",
    "#Provide the text in search job and location\n",
    "job_title.send_keys(\"Data Scientist\")\n",
    "job_location.send_keys(\"Bangalore\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"06ecc24a-12a9-4483-ba7c-9fc7dd9d687e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"3074c0ca-5150-480e-8699-b772cd1e0921\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"e29b20fd-f8c8-48a6-89c2-6bea263d3fe4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"33d6555b-0fa8-406b-95a8-9457488ef4e3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"961e0703-f7d2-4d42-9069-c7aaac09055a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"663c8976-9c0f-4625-a1ee-361fe9aec162\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"3997f60f-133f-49f3-861e-77652a820fb8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"b6431478-6cb6-4925-ba9d-5700ad9d14d3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"4b24adcd-fb72-483b-8340-a67a249d4792\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"d621e17c-3f47-4003-985c-6f5dc97b0694\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"7d287070-b554-47f3-ad8d-e3283aafdcf2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"e6430202-bccc-4489-bb80-b3ec5110dc86\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"f86193c9-5bf9-43f1-b534-22883c7092e2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"e6207a1f-ea6a-49ce-a790-0d8a3bee58c8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"fffb506d-7748-4085-b1d9-b044930a439b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"78bc4e1d-c2c0-4277-bf80-e77075355ec1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"9cf29531-e22f-4b90-9c32-389a2b3c727a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"b6ae4ed8-16b3-4708-8510-d4a854e335e2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"d8e38727-53e9-4e85-8d8e-3ca41a3abda1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"5367286f-4748-4ae4-a57b-64ac6deecc21\")>]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Job Title Fetching\n",
    "job_title = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Scientist',\n",
       " 'Principal Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior/Staff Data scientist',\n",
       " 'Senior Data Scientist I',\n",
       " 'IDM - Lead Data Scientist',\n",
       " 'Senior/Lead Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Principal Data Scientist']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fetching the Job Title\n",
    "title=[]  \n",
    "\n",
    "#We need to fetch data for the first 10 job results\n",
    "for x in job_title[:10]:\n",
    "    title.append(x.text)\n",
    "\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"e9a1179b-baf3-44cb-89c1-c23d60f9b432\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"23d81ca0-cf88-4da2-a5c5-593a2bb059b3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"4e738431-f102-4009-b9e3-e53e3acc8e8b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"9ef6b355-2383-4dfc-9358-410fc76b113e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"e167dcee-b012-460a-9de7-891356ce5215\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"9ea19fe7-3c16-496a-8654-d212f58b0f7b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"7c8c0273-72ab-4392-bbc9-2d8de4477d94\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"24506834-37d1-481e-9518-ba59529943cb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"910f6498-ca01-4106-9171-a1fe994a54cd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"22853687-260e-4c7b-8f34-375d71dbe05d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"74233006-cb83-47e1-852f-811ac6034ae4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"761f06d8-79b7-4f17-800d-caccb86386cb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"5183ae08-35fc-44a0-867d-df8270afaf2c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"d5d9da04-0d0c-4d5a-83ce-ca3c5444bd31\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"5b352c38-4dec-4c63-83af-8d60e74cbdc9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"b5e54858-457c-4712-8fce-36b0d4280262\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"d4614ee8-a4de-4b89-b8ad-e95a17b2babe\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"440d3606-d429-4b41-9bd0-8cc8fc889f10\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"9f751b7d-5119-434f-9fc8-7c6b73228155\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"49211ed1-a99a-4516-8125-162436ad1a51\")>]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fetching the job location\n",
    "job_location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru, Pune',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Job Location Update\n",
    "jb_location=[] \n",
    "\n",
    "#Fetching data for 10 records\n",
    "for x in job_location[:10]:\n",
    "    jb_location.append(x.text)\n",
    "jb_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"f6a6e56e-c659-4106-988a-e12dc4edf5b9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"950d3da5-db4b-4309-ad55-5e20a3d9de9d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"94cddbbe-c0b4-4fa0-a435-2b876c858d57\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"a3b6bf37-ac5f-4384-80b5-2ae9c0b3a179\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"b8750cc6-6d65-452a-bb55-5a50f8b450d9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"031d61a9-2701-4d93-8a6f-6d66cdff9d48\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"e3913f2b-b68d-4340-9f4a-1742ea2910ad\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"e3b92935-e863-4b94-89bf-b2d7e9128119\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"0d918455-3f11-44cd-94f7-6769e635fe58\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"6d44272c-037b-41f6-801b-ac59152c96f0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"f591989c-dc58-46d7-a20e-701a00bc9c44\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"21c8d2e1-4669-4acb-a05d-5623e311e3a7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"75dbf60c-d476-470b-b5ce-83c38409a356\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"073122ef-1403-4cab-a475-539cffddfa4e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"cfbff063-43bb-422c-b1ce-1852a6d5e005\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"caf824bf-76ac-4653-bba0-c76dde926802\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"b5abd0b8-f70b-4502-8b10-1361eb6c53af\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"a3840c16-db28-4c6e-a502-21f3861f33ce\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"642ac466-3356-4beb-b3d8-d043d7445b9b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c59c79c2df56e053dd160d2e0f94824f\", element=\"00cd2a39-7078-447c-af1f-ee6a699ec474\")>]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Company name\n",
    "comp_name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "comp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24/7 Customer',\n",
       " '24/7 Customer',\n",
       " 'Wipro Limited',\n",
       " 'Pluto7',\n",
       " 'Vmware',\n",
       " 'Philips India Limited',\n",
       " 'Philips India Limited',\n",
       " 'AUREUSTECH SYSTEMS PRIVATE LIMITED',\n",
       " 'Pluto7',\n",
       " 'Philips India Limited']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Company\n",
    "company_name=[]  #Empty list\n",
    "\n",
    "#Loop for 10 records\n",
    "for i in comp_name[:10]:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job description Brief about the Role The Platforms team of the Data Science Group at [24]7.ai builds scalable AI to aid in conversational AI, agent assist solutions, and ad personalization for the Cloud. We are looking for a highly motivated and qualified data scientist to build some of our AI initiatives. This role is ideal for candidates with strong, hands-on skills in machine learning and natural language processing. Educational Qualifications: Bachelors, Master’s or PhD degree from reputed universities or institutes in one of the following disciplines: Artificial Intelligence / Machine Learning Data Science Cognitive Computing Computational Linguistics Computer Science Requirements 4+ years of experience with general purpose programming languages e.g., Python, C/C++, Java 4+ years of hands-on experience in machine learning Experience in various deep learning models, e.g., transformers, LSTMs, RNNs Experience in solving problems related to Natural Language Processing (NLP), Natural Language Understanding (NLU), and Natural Language Generation (NLG) Experience with machine learning platforms such as TensorFlow, TensorFlow Extended, PyTorch Experience building and deploying machine learning models on the Cloud (Google Cloud, Azure, AWS) Experience with production architecture of machine learning systems Good to have exposure to conversational AI, AI-based question-answering systems, AI-based compliance and monitoring systems, and ad personalization Good to have exposure to MLOps pipelines and Kubeflow Excellent communication skills Ability to collaborate cross-functionally Good presentation skills Attention to detail Responsibilities Collaborate with the Engineering and Product teams to implement machine learning models into the products and offerings of [24]7.ai Collaborate with your team members. Be responsible for implementing the machine learning models, testing them, refining them, and taking them to production Collaborate within the Data Science Group to review and refine your work to ensure the highest quality Take end-to-end ownership of AI initiatives Proactively discuss ideas for feature enhancements with the data science leadership and product leadership RoleTechnical Architect Industry TypeIT Services & Consulting Functional AreaIT Software - Other Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :B.Tech/BE in Computers PG :M.Tech/ME in Computers Key Skills Computer sciencedata scienceArtificial IntelligenceMachine learningLinguisticsNatural language processingNew product developmentCustomer experienceMonitoringPython',\n",
       " 'Job description Brief about the Role The Platforms team of the Data Science Group at [24]7.ai builds scalable AI to aid in conversational AI, agent assist solutions, and ad personalization for the Cloud. We are looking for a highly motivated and qualified data scientist to lead some of our AI initiatives. This role is ideal for candidates with strong, hands-on skills in machine learning and natural language processing. Educational Qualifications: Bachelors, Master’s or PhD degree from reputed universities or institutes in one of the following disciplines: Artificial Intelligence / Machine Learning Data Science Cognitive Computing Computational Linguistics Computer Science Requirements 10+ years of experience with general purpose programming languages e.g., Python, C/C++, Java 10+ years of hands-on experience in machine learning 4+ years of experience leading multiple machine learning projects simultaneously Extensive experience in various deep learning models, e.g., transformers, LSTMs, RNNs Experience in solving problems related to Natural Language Processing (NLP), Natural Language Understanding (NLU), and Natural Language Generation (NLG) Experience with machine learning platforms such as TensorFlow, TensorFlow Extended, PyTorch Experience building and deploying machine learning models on the Cloud (Google Cloud, Azure, AWS) Experience with production architecture of machine learning systems Experience leading and mentoring a team of data scientists Good to have exposure to conversational AI, AI-based question-answering systems, and AI-based compliance and monitoring systems Good to have exposure to MLOps pipelines and Kubeflow Excellent communication skills Ability to collaborate cross-functionally Good presentation skills Attention to detail Responsibilities Collaborate with the Engineering and Product teams to define and build AI models into the products and offerings of [24]7.ai Lead the development of machine learning models and their production architecture Collaborate within the Data Science Group to review and refine your work Lead and own the AI initiatives end to end for at least 2-3 products Lead and mentor a team of data scientists, and be responsible for their work allocation and tracking Work with the data science leadership and product leadership to define the AI roadmap for the company RoleTechnical Architect Industry TypeIT Services & Consulting Functional AreaIT Software - Application Programming, Maintenance Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :B.Tech/BE in Computers PG :M.Tech/ME in Computers Key Skills Computer sciencedata scienceArtificial IntelligenceMachine learningLinguisticsNatural language processingNew product developmentPrincipalMonitoringPython',\n",
       " 'Job description Role: Data Scientist  Roles and Responsibilities Suitable candidates will be part of Wipro Digital-Intelligent Enterprise practice. The role entails leveraging Data Science and Machine Learning to solve typical problems within an organization and create IP that could be deployed in a productized mode. This will entail significant hands-on work on multiple Big Data Technologies, Data Analysis, Identifying data patterns, ML models, Insights generation. The role entails deployment in a customer context and managing customer expectations.  Technical Skills Required: Hands on with Python or R Analytics using industry leading BI tools and technologies Implementation knowledge of supervised\\\\un-supervised machine learning algorithms Good statistical analysis skills for data pre-processing and data wrangling Experienced in using big data frameworks like Hadoop Knowledge of business intelligence tools or reporting tools  Data Preparation for Modeling Missing Data Imputation,Outlier Treatment Scaling, Normalization, Standardization Encoding for Categorical Variables Oversampling\\\\Undersampling for reducing class imbalance  Experience in building solutions using Model Library Feature Selection Tree-based Ensemble Models Gradient\\\\Adaptive Boosted Trees Hyper-parameter tuning Building Prediction mechanisms using methods like Logistic regression, voting classifier stacking etc  RoleData Analyst Industry TypeIT Services & Consulting Functional AreaAnalytics & Business Intelligence Employment TypeFull Time, Permanent Role CategoryAnalytics & BI Education UG :B.Tech/BE in Any Specialization Key Skills Big DataMachine LearningPython Data ScienceRLogistic RegressionData WranglingHadoopData AnalysisStatistical Analysis Skills highlighted with ‘‘ are preferred keyskills',\n",
       " 'Job description Responsibilities: Build and Optimize Machine Learning models. Work with large/complex datasets to solve difficult and non-routine analysis problems, applying advanced analytical methods as needed. Build and prototype data pipelines for analysis at scale. Work cross-functionally with Business Analysts and Data Engineers to help develop cutting edge and innovative artificial intelligence and machine learning models. Make recommendations for selections on machine learning models. Drive accuracy levels to the next stage of the given ML models. Experience in developing visualization and User Good exposure in exploratory data analysis Strong experience in Statistics and ML algorithms. Minimum qualifications: (2-4) years of relevant work experience in ML and advanced data analytics(e.g., as a Machine Learning Specialist / Data scientist ). Strong Experience using machine learning and artificial intelligence frameworks such as Tensorflow, sci-kit learn, Keras using python. Good in Python/R/SAS programming. Understanding of Cloud platforms like GCP, AWS, or other. Preferred qualifications: Work experience in building data pipelines to ingest, cleanse and transform data. Applied experience with machine learning on large datasets and experience translating analysis results into business recommendations. Demonstrated skills in selecting the right statistical tools given a data analysis problem. Demonstrated effective written and verbal communication skills. Demonstrated willingness to both teach others and learn new techniques RoleSoftware Developer Industry TypeManagement Consulting Functional AreaIT Software - System Programming Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :B.Tech/BE in Any Specialization PG :Any Postgraduate Key Skills SANERPData analysisPrototypeMachine learningHealthcareApplication developmentciscoAnalyticsPython',\n",
       " 'Job description About You You are a highly motivated person with a solid understanding of mainstream ML/AI algorithms. You have hands-on experience using popular frameworks to train, test, and deploy ML models in production environments. You have experience with statistical methods and tools for analyzing large and imperfect data sets to identify patterns, extract meaningful signals from noise, and build ML models. You are comfortable with building your own tools and infrastructure, when necessary. You are an excellent communicator and are able to convey complex ideas to different audiences. You have intense curiosity mixed with healthy skepticism you are interested in any problem where data can be applied, and you understand the importance of vetting analysis to make sure data isn t misrepresented. Above all, you are excited about working with data, and you know how to realize your ideas with code. Responsibilities Uncover business and product opportunities by efficient and actionable analysis, and present findings in a clear manner. Process large amounts data, perform data cleansing, and verify the integrity of data. Develop ML/AI models to address use-cases in the areas of security, IT automation, user experience, and optimization. Build prototypes of systems to demonstrate feasibility of proposed ML models. Collaborate with engineers and assist them with the design and implementation of ML pipelines (data ingestion, feature extraction, training, testing and validation, inference, and continual learning) in production systems. Analyze the effectiveness of new features after they are introduced in the product. Follow relevant work being done in academic and other research organizations; be as close as possible to the state-of-the-art in the fields of ML and AI. Required Qualifications 10+ years of work experience, of which 5+ years of experience in data science or machine learning working with large data sets; experience in software engineering desirable. First-hand experience working with machine learning models and techniques such as decision tree, gradient boosted tree, random forest, ensemble methods, clustering, principal component analysis, and recommendation systems. Knowledge of neural networks, deep learning, reinforcement learning, and natural language processing (NLP) will be useful. Proficient in Python. Working knowledge of other programming languages such as Java, Scala, or C++ is desirable. Knowledge of different SQL and NoSQL database systems. Solid understanding of concepts from statistics such as distributions, hypothesis testing, Bayesian methods, maximum likelihood estimation. Experience using Python statistical processing libraries such as NumPy, Pandas, SciPy, Scikit-Learn, etc. Competency with data visualization (Matplotlib, Seaborn, etc.) and analysis tools (Tableau, Presto, etc.) Familiarity with large-scale data processing frameworks such as Apache Spark, and cloud computing environments such as Amazon Web Services (AWS). Exposure to machine learning frameworks such as Keras, TensorFlow, MXNet, Caffe2, PyTorch, H2O.ai, Amazon SageMaker is a plus. MS or above in Computer Science, Electrical Engineering, Mathematics, Statistics, Physics or equivalent, or commensurate work experience. RoleTechnical Architect Industry TypeIT Services & Consulting Functional AreaIT Software - Application Programming, Maintenance Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :B.Tech/BE in Computers PG :M.Tech/ME in Computers Key Skills Computer scienceVMwareCloud computingC++AutomationNetworkingMachine learningVirtualizationSQLPython',\n",
       " 'Job description Job Responsibilities Use predictive modeling to increase and optimize customer experiences, revenue generation, campaign optimization and other business outcomes Work with product management to develop data use cases and embed predictive models in workflows on resource constrained platforms and cloud enabled. Selecting features, building and optimizing classifiers using machine learning and deep learning techniques Collaborates with Data Engineers to enhance data collection and ingestion/curation techniques to include information that is relevant for building analytic systems Processing, cleansing, and verifying the integrity of data used for analysis Develop processes and tools to monitor and analyze model performance and data accuracy. Life cycle management of predictive models. Adherence to compliance procedures in accordance with regulatory standards, requirements, and policies. Managing and designing the reporting environment, including data sources security, and metadata. Job Qualifications: Master s degree or PhD in Computer Science, Information management, Statistics or related field, with 10+ years of experience in the Consumer or Healthcare industry manipulating data sets and building predictive models with focus on product development Experience in statistical modelling, machine learning, data mining, unstructured data analytics and natural language processing. Sound understanding of - Bayesian Modelling, Classification Models, Cluster Analysis, Neural Network, Nonparametric Methods, Multivariate Statistics, etc. Strong hands on knowledge of ML techniques like regression algorithms, K-NN, Na ve Bayes, SVM and ensemble techniques like Random forest, AdaBoost etc Having strong knowledge in unsupervised learning algorithms using Neural networks and Deep-Learning Strong knowledge in Data Wrangling and Exploration techniques to identify the patterns, trends and outliners. Deep knowledge and practical experience with data science toolkits, such as NumPy, Pandas, scikit-learn or equivalent Experience with data visualization tools, such as QlikView, Matplotlib, seaborn or equivalent tools. Proficiency in using query languages, such as SQL, PL/SQL Hands on experience in the one or more databases like Hadoop, AWS Redshift, Snowflake etc. Good applied statistics skills, such as distributions, statistical testing, regression, etc. Good ETL scripting and programming skills, such as Python, R or Scala to integrate developed solution into the proposition. A team player capable of working and integrating across cross-functional team for implementing project requirements. Experience in technical requirements gathering and documentation. Ability to work effectively and independently in a fast-paced global collaborative agile team environment with tight deadlines A flexible, pragmatic and collaborative team player with innate ability to engage with stakeholders at all levels in the organization. A self-starter with high levels of drive, energy, resilience and a desire for professional excellence with a passion for data and data science RoleSoftware Developer Industry TypeMedical Services / Hospital Functional AreaIT Software - Application Programming, Maintenance Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :Any Graduate PG :Post Graduation Not Required Key Skills Product managementComputer sciencemetadataMachine learningAgilePLSQLHealthcareQlikViewData miningPython',\n",
       " 'Job description Your responsibilities Ensure strategic direction for data science capabilities for Philips is created and kept up to date on a regular basis Continuously evaluate the latest techniques in Artificial intelligence, machine learning, robotics, statistical analysis Implement advanced algorithms for business problems based on statistical analysis, coding, deep learning, advanced data mining techniques etc. Develop new algorithms if necessary, to bring predictive, advanced statistics / learning based solutions Develop algorithms to further automate processes and feed insights back into PIL for better business outcome Co-create with business / market / functions or IT platforms on requirements Ensure quality of data and solution developed Lead and drive data mining, creating algorithms, collection of data, collection of procedures during the design, build phases of a project Lead and drive in deploy and testing of the solutions and insights Spot and evaluate emerging/cutting edge, open source, data science/machine learning libraries You are part of: You will be part of Group IT , Information and Data Management team that drives business impact through Data Science and Advanced analytics. A team that instigates collaboration across diverse teams globally to manage Data as an asset at Philips. Core competencies needed to be successful: A Master s Degree or PhD in Computer Science, Econometrics, Artificial Intelligence, Applied Mathematics, Statistics or equivalent; 10-15 years of overall experience in data science, data analytics roles 10+ years of experience in multiple of machine learning, data mining, deep learning, artificial intelligence, pattern recognition areas Experience in driving implementation of solutions, data and algorithms on data warehouse and lakes like Azure , AWS, SQL etc Demonstrable advanced programming experience in Python or another programming language such as Azure ML/R/Python etc ; Strong analytical and social skills and the capability to translate data intelligence into valuable insights for the senior stakeholders in the company Ability to formulate multiple complex business problems into hypothesis and proof of concepts for testing Manage Projects and lead a sub-portfolio of data science project teams to deliver results Coach, Guide and direct teams of internal and vendor resources Collaborate across IT platform teams to deploy solutions and drive continuous improvements Manage senior stakeholder in the company in a matrix organization i.e. Market / BG / Function leaders RoleTeam Lead/Technical Lead Industry TypeMedical Services / Hospital Functional AreaIT Software - Application Programming, Maintenance Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :Any Graduate PG :Post Graduation Not Required Key Skills Computer scienceData managementCodingAnalyticalMachine learningHealthcareData miningRoboticsSQLPython',\n",
       " 'Job description Responsibilities Identify valuable data sources and automate collection processes Undertake preprocessing of structured and unstructured data Analyze large amounts of information to discover trends and patterns Build predictive models and machine-learning algorithms Combine models through ensemble modeling Present information using data visualization techniques Propose solutions and strategies to business challenges Collaborate with engineering and product development teams  Requirements Proven experience as a Data Scientist or Data Analyst Experience in data mining, Deep Learning Understanding of machine-learning and operations research Experience with NLP Experience with Python Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop) Analytical mind and business acumen Very Strong math skills (e.g. statistics, algebra etc.,) Problem-solving aptitude Excellent communication and presentation skills   RoleProduct Manager Industry TypeIT Services & Consulting Functional AreaIT Software - Application Programming, Maintenance Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education PG :Any Postgraduate Doctorate :Any Doctorate Key Skills NLPAlgorithmsData AnalysisData MiningData VisualizationTableauStatisticsDeep LearningPython',\n",
       " 'Job description Responsibilities: Build NLP based models Build and Optimize Machine Learning models. Work with large/complex datasets to solve difficult and non-routine analysis problems, applying advanced analytical methods as needed. Build and prototype data pipelines for analysis at scale. Work cross-functionally with Business Analysts and Data Engineers to help develop cutting edge and innovative artificial intelligence and machine learning models. Make recommendations for selections on machine learning models. Drive accuracy levels to the next stage of the given ML models. Experience in developing visualization and User Good exposure in exploratory data analysis Strong experience in Statistics and ML algorithms. Minimum qualifications: (3-6) years of relevant work experience in ML and advanced data analytics(e.g., as a Machine Learning Specialist / Data scientist ). Strong Experience using machine learning and artificial intelligence frameworks such as Tensorflow, sci-kit learn, Keras using python. Good in Python/R/SAS programming. Understanding of Cloud platforms like GCP, AWS, or other. Preferred qualifications: Work experience in building data pipelines to ingest, cleanse and transform data. Applied experience with machine learning on large datasets and experience translating analysis results into business recommendations. Demonstrated skills in selecting the right statistical tools given a data analysis problem. Demonstrated effective written and verbal communication skills. Demonstrated willingness to both teach others and learn new techniques RoleClinical Research Associate/Scientist Industry TypeManagement Consulting Functional AreaMedical, Healthcare, R&D, Pharmaceuticals, Biotechnology Employment TypeFull Time, Permanent Role CategoryR&D Education UG :B.Tech/BE in Any Specialization PG :Any Postgraduate Key Skills SANERPData analysisPrototypeMachine learningHealthcareApplication developmentciscoAnalyticsPython',\n",
       " 'Job description In this role, you have the opportunity to Provide data science solutions using advanced techniques, tools and methods to complex business problems. Create and maintain standards around data science for the company. Partner with businesses, markets and functions. Reporting Head of Information Data Management   You are responsible for Co-create with business / market / functions or IT platforms on data science projects to meet the business need for insights and analytics using sophisticated data science techniques i.e. automation, crunching big data sets, machine learning or AI Setup projects to drive the business needs Participate in budgeting cycle, leading resources and running vendors Work on continuously updating data science strategy including evaluate emerging/cutting edge, open source, data science/machine learning libraries/big data platforms Strong proven experience in solving business problems through data science techniques, statistical modeling where simple analysis will not be sufficient Provide technical and people leadership to the data science team Ability to formulate multiple sophisticated business problems into hypothesis and proof of concepts for testing Coach, Guide and lead teams of internal and vendor resources Direct a team of 10-12 FTE data scientists and their priorities together with the partners and data information strategy Lead PL for the sub-department and the data science project portfolio Lead senior partner in the company in a matrix organization up to Executive committee levels, Market / BG / Function leaders Formulate strategies for incorporating new, latest and cutting-edge techniques and tools To succeed in this role, you should have the following skills and experience Demonstrable sophisticated programming experience in Python or another programming language such as Java/C/C++/R; Strong analytical and interpersonal skills and the capability to translate data intelligence into valuable insights for the senior partners in the company Experience in data analytics and in statistical (regression, clustering and classification), descriptive and diagnosis methods; knowledge of forecasting methods A Master s Degree or PhD in Computer Science, Econometrics, Artificial Intelligence, Applied Mathematics, Statistics or equivalent; Certifications or training in leadership MBA is a plus 15+ years of overall experience in data science, data analytics roles proven experience in multiple of machine learning, data mining, deep learning, artificial intelligence, pattern recognition areas demonstrated ability in creating and leading data science and analytics teams validated experience in creating and leading data science and / or data analytics strategy demonstrated ability in working in multinational companies with matrix structures including handling conflicting priorities from multiple partners RoleTeam Lead/Technical Lead Industry TypeMedical Services / Hospital Functional AreaIT Software - Application Programming, Maintenance Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :Any Graduate PG :Post Graduation Not Required Key Skills Computer scienceC++AutomationData managementAnalyticalBudgetingData miningEconometricsForecastingMonitoring']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping Job Description from next page\n",
    "links=[x.get_attribute(\"href\")for x in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "jb_description = []\n",
    "\n",
    "for link in links[0:10]:\n",
    "    driver.get(link)\n",
    "    desc = driver.find_element_by_xpath(\"//*[@id='root']/main/div[2]/div[2]/section[2]\").text\n",
    "    description=desc.replace(\"Contact Person\",\"@@@@@\")\n",
    "    description = description.replace(\"\\n\",\" \")\n",
    "    description= description.split(\"@@@@@\")\n",
    "    jb_description.append(description[0])\n",
    "    \n",
    "jb_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#Length validation of all the data\n",
    "print(len(title),len(jb_location),len(company_name),len(jb_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>24/7 Customer</td>\n",
       "      <td>Job description Brief about the Role The Platf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>24/7 Customer</td>\n",
       "      <td>Job description Brief about the Role The Platf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>Job description Role: Data Scientist  Roles an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Pluto7</td>\n",
       "      <td>Job description Responsibilities: Build and Op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior/Staff Data scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Vmware</td>\n",
       "      <td>Job description About You You are a highly mot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Job description Job Responsibilities Use predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IDM - Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Job description Your responsibilities Ensure s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior/Lead Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>AUREUSTECH SYSTEMS PRIVATE LIMITED</td>\n",
       "      <td>Job description Responsibilities Identify valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Pluto7</td>\n",
       "      <td>Job description Responsibilities: Build NLP ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Job description In this role, you have the opp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Job_Title  \\\n",
       "0        Senior Data Scientist   \n",
       "1     Principal Data Scientist   \n",
       "2               Data Scientist   \n",
       "3        Senior Data Scientist   \n",
       "4  Senior/Staff Data scientist   \n",
       "5      Senior Data Scientist I   \n",
       "6    IDM - Lead Data Scientist   \n",
       "7   Senior/Lead Data Scientist   \n",
       "8               Data Scientist   \n",
       "9     Principal Data Scientist   \n",
       "\n",
       "                                        Job_Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Hyderabad/Secunderabad, Bangalore/Bengaluru, Pune   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                         Company name  \\\n",
       "0                       24/7 Customer   \n",
       "1                       24/7 Customer   \n",
       "2                       Wipro Limited   \n",
       "3                              Pluto7   \n",
       "4                              Vmware   \n",
       "5               Philips India Limited   \n",
       "6               Philips India Limited   \n",
       "7  AUREUSTECH SYSTEMS PRIVATE LIMITED   \n",
       "8                              Pluto7   \n",
       "9               Philips India Limited   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Job description Brief about the Role The Platf...  \n",
       "1  Job description Brief about the Role The Platf...  \n",
       "2  Job description Role: Data Scientist  Roles an...  \n",
       "3  Job description Responsibilities: Build and Op...  \n",
       "4  Job description About You You are a highly mot...  \n",
       "5  Job description Job Responsibilities Use predi...  \n",
       "6  Job description Your responsibilities Ensure s...  \n",
       "7  Job description Responsibilities Identify valu...  \n",
       "8  Job description Responsibilities: Build NLP ba...  \n",
       "9  Job description In this role, you have the opp...  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New dataframe for the data\n",
    "job_details=pd.DataFrame({})\n",
    "job_details['Job_Title']=title\n",
    "job_details['Job_Location']=jb_location\n",
    "job_details['Company name']=company_name\n",
    "job_details['Job Description']=jb_description\n",
    "job_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Csv file extraction\n",
    "job_details.to_csv(\"DataScientist_Bangalore_Naukrijobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Closing the driver finally\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the\n",
    "webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoking chromedriver.exe file\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")\n",
    "#Opening the website\n",
    "URL = \"https://www.naukri.com/\"\n",
    "driver.get(URL)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the elements\n",
    "job_title = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_button = driver.find_element_by_class_name(\"btn\")\n",
    "#Provide the text in search job and location\n",
    "job_title.send_keys(\"Data Scientist\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter with Delhi/NCR\n",
    "filt_location=driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft']\")\n",
    "for x in filt_location:\n",
    "    if x.text=='Delhi / NCR':\n",
    "        x.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the salary with 3-6 Lakhs\n",
    "filt_salary=driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft']\")\n",
    "for x in filt_salary:\n",
    "    if x.text=='3-6 Lakhs':\n",
    "        x.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "job_title = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_title\n",
    "\n",
    "#Fetching the Job Title\n",
    "title=[]  \n",
    "\n",
    "#We need to fetch data for the first 10 job results\n",
    "for x in job_title[:10]:\n",
    "    title.append(x.text)\n",
    "\n",
    "title\n",
    "\n",
    "\n",
    "#Fetching the job location\n",
    "job_location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "job_location\n",
    "\n",
    "\n",
    "#Job Location Update\n",
    "jb_location=[] \n",
    "\n",
    "#Fetching data for 10 records\n",
    "for x in job_location[:10]:\n",
    "    jb_location.append(x.text)\n",
    "jb_location\n",
    "\n",
    "\n",
    "\n",
    "#Company name\n",
    "comp_name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "comp_name\n",
    "\n",
    "\n",
    "#Company\n",
    "company_name=[]  #Empty list\n",
    "\n",
    "#Loop for 10 records\n",
    "for i in comp_name[:10]:\n",
    "    company_name.append(i.text)\n",
    "company_name\n",
    "\n",
    "\n",
    "#Experience required Data\n",
    "exp_required=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "exp_required\n",
    "\n",
    "\n",
    "#Experience data fetching\n",
    "experience=[]  \n",
    "\n",
    "#For loop for 10 records\n",
    "for i in exp_required[:10]:\n",
    "    experience.append(i.text)\n",
    "experience\n",
    "\n",
    "\n",
    "#Length validation of all the data\n",
    "print(len(title),len(jb_location),len(company_name),len(experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist -Delhi</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>CHANGE LEADERS CONSULTING</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Text NLP | Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Acidaes Solutions Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "2                              Data Scientist -Delhi   \n",
       "3                  Data Scientist - Text NLP | Noida   \n",
       "4                                     Data Scientist   \n",
       "5              Data Scientist - Machine Learning/NLP   \n",
       "6              Data Scientist - Machine Learning/NLP   \n",
       "7  Data analytics / Data scientist intern (work f...   \n",
       "8              Chaayos is Looking For Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job_Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "2                                          New Delhi   \n",
       "3                                              Noida   \n",
       "4                                              Noida   \n",
       "5                                   Gurgaon/Gurugram   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7          Kolkata, Bangalore/Bengaluru, Delhi / NCR   \n",
       "8                                          New Delhi   \n",
       "9      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "\n",
       "                            Company name Experience  \n",
       "0     Inflexion Analytix Private Limited    0-3 Yrs  \n",
       "1              GABA Consultancy services    0-0 Yrs  \n",
       "2              CHANGE LEADERS CONSULTING    5-8 Yrs  \n",
       "3            Acidaes Solutions Pvt. Ltd.    3-5 Yrs  \n",
       "4  NEC CORPORATION INDIA PRIVATE LIMITED    3-8 Yrs  \n",
       "5                                 TalPro    2-6 Yrs  \n",
       "6                                 TalPro    2-4 Yrs  \n",
       "7                         TalkValley LLC    0-5 Yrs  \n",
       "8  Chaayos (Sunshine Teahouse Pvt. Ltd.)    0-5 Yrs  \n",
       "9                      Fractal Analytics    3-7 Yrs  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New dataframe for the data\n",
    "job_details=pd.DataFrame({})\n",
    "job_details['Job_Title']=title\n",
    "job_details['Job_Location']=jb_location\n",
    "job_details['Company name']=company_name\n",
    "job_details['Experience']=experience\n",
    "job_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Csv file extraction\n",
    "job_details.to_csv(\"DataScientist_DelhiNCR_Naukrijobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida”\n",
    "in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown\n",
    "page.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoking chromedriver.exe file\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")\n",
    "#Opening the website\n",
    "URL = \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(URL)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Job and Location search\n",
    "jb_search=driver.find_element_by_id('sc.keyword')\n",
    "loc_search=driver.find_element_by_id('sc.location')\n",
    "\n",
    "#Sending the values for job and location search\n",
    "jb_search.send_keys(\"Data Scientist\")\n",
    "loc_search.send_keys(\"Noida\")\n",
    "\n",
    "#Searching the inputs by using the search button and clicking it\n",
    "driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company name</th>\n",
       "      <th>Days posted for Job</th>\n",
       "      <th>Company Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard Chartered</td>\n",
       "      <td>12 days ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AstraZeneca</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>30 days ago+</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell</td>\n",
       "      <td>30 days ago+</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>14 days ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Buckman</td>\n",
       "      <td>11 days ago</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sybrant Data</td>\n",
       "      <td>30 days ago+</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Caterpillar</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IDP Education Ltd</td>\n",
       "      <td>14 days ago</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HDFC Bank</td>\n",
       "      <td>30 days ago+</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Company name Days posted for Job Company Rating\n",
       "0  Standard Chartered         12 days ago            3.8\n",
       "1         AstraZeneca          5 days ago            4.2\n",
       "2              PayPal        30 days ago+            4.3\n",
       "3               Shell        30 days ago+            4.1\n",
       "4                             14 days ago            4.1\n",
       "5             Buckman         11 days ago            3.6\n",
       "6        Sybrant Data        30 days ago+            3.9\n",
       "7         Caterpillar          6 days ago            4.0\n",
       "8   IDP Education Ltd         14 days ago            3.6\n",
       "9           HDFC Bank        30 days ago+            3.2"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Company name\n",
    "comp_name=driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a/span\")\n",
    "comp_name\n",
    "\n",
    "#Extracting the company from the tags\n",
    "company=[]  \n",
    "\n",
    "\n",
    "for i in comp_name[:10]:\n",
    "    company.append(i.text)\n",
    "company\n",
    "\n",
    "#No of days when job was posted\n",
    "noofdays=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "noofdays\n",
    "\n",
    "#Extracting the days\n",
    "number_of_days=[]  \n",
    "\n",
    "for i in noofdays[:10]:\n",
    "    number_of_days.append(i.text.replace('d',' days ago'))\n",
    "number_of_days\n",
    "\n",
    "#Company rating extraction\n",
    "comp_rating=driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "comp_rating\n",
    "\n",
    "#Extracting the ratings\n",
    "comp_ratings=[]  \n",
    "\n",
    "for i in comp_rating[:10]:\n",
    "    comp_ratings.append(i.text)\n",
    "comp_ratings\n",
    "\n",
    "#Length of the data\n",
    "print(len(company),len(number_of_days),len(comp_ratings))\n",
    "\n",
    "#New dataframe creation\n",
    "job_details=pd.DataFrame({})\n",
    "job_details['Company name']=company\n",
    "job_details['Days posted for Job']=number_of_days\n",
    "job_details['Company Rating']=comp_ratings\n",
    "job_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Csv file extraction\n",
    "job_details.to_csv(\"DataScientist_Noida_GlassDoor_Ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation\n",
    "in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page \n",
    "5. You have to scrape whole data from this webpage\n",
    "6. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "7. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoking chromedriver.exe file\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")\n",
    "#Opening the website\n",
    "URL = \"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(URL)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location and Job Search\n",
    "job_search=driver.find_element_by_id('KeywordSearch')\n",
    "location_search=driver.find_element_by_id('LocationSearch')\n",
    "\n",
    "#Sending the details to the webpage\n",
    "job_search.send_keys(\"Data Scientist\")\n",
    "location_search.clear()\n",
    "location_search.send_keys(\"Noida\")\n",
    "\n",
    "driver.find_element_by_xpath(\"//button[@id='HeroSearchButton']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Number of salaries</th>\n",
       "      <th>Average salary</th>\n",
       "      <th>Minimum salary</th>\n",
       "      <th>Maximum salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company Name, Number of salaries, Average salary, Minimum salary, Maximum salary]\n",
       "Index: []"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_name=driver.find_elements_by_xpath(\"//div[@class='d-flex']/div[2]/p[2]\")\n",
    "comp_name\n",
    "\n",
    "#Extracting the company name from the tags\n",
    "company=[]  \n",
    "\n",
    "\n",
    "for i in comp_name[:10]:\n",
    "    company.append(i.text)\n",
    "company\n",
    "\n",
    "#Extracting the number of salaries\n",
    "no_salaries=driver.find_elements_by_xpath(\"//div[@class='d-flex']/div[2]/p[5]\")\n",
    "no_salaries\n",
    "\n",
    "#Extracting the text from the tags\n",
    "no_of_salaries=[]  #Empty list\n",
    "\n",
    "#We are running a for loop for first 10 results \n",
    "for i in no_salaries[:10]:\n",
    "    no_of_salaries.append(i.text)\n",
    "no_of_salaries\n",
    "\n",
    "#Extracting the average salary\n",
    "avg_sal=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']\")\n",
    "avg_sal\n",
    "\n",
    "#Extracting the text from the tags\n",
    "avg_salary=[]  #Empty list\n",
    "\n",
    "#As we need to scrap data for the first 10 job results, we are running a for loop for first 10 results only\n",
    "for i in avg_sal[:10]:\n",
    "    avg_salary.append(i.text.replace('\\n',''))\n",
    "avg_salary\n",
    "\n",
    "#Extracting the tags having minimum salary\n",
    "min_sal=driver.find_elements_by_xpath(\"//div[@class='col-3 offset-1 d-none d-md-block']/div/div[2]/span[1]\")\n",
    "min_sal\n",
    "\n",
    "#Extracting the text from the tags\n",
    "min_salary=[]  #Empty list\n",
    "\n",
    "#We are running a for loop for first 10 results \n",
    "for i in min_sal[:10]:\n",
    "    min_salary.append(i.text)\n",
    "min_salary\n",
    "\n",
    "#Extracting the maximum salary\n",
    "max_sal=driver.find_elements_by_xpath(\"//div[@class='col-3 offset-1 d-none d-md-block']/div/div[2]/span[2]\")\n",
    "max_sal\n",
    "\n",
    "#Extracting the max salary \n",
    "max_salary=[]  #Empty list\n",
    "\n",
    "#We are running a for loop for first 10 results \n",
    "for i in max_sal[:10]:\n",
    "    max_salary.append(i.text)\n",
    "max_salary\n",
    "\n",
    "#Checking out the length of the datas \n",
    "print(len(company),len(no_of_salaries),len(avg_salary),len(min_salary),len(max_salary))\n",
    "\n",
    "#Creating a new dataframe for saving the data\n",
    "job_details=pd.DataFrame({})\n",
    "job_details['Company Name']=company\n",
    "job_details['Number of salaries']=no_of_salaries\n",
    "job_details['Average salary']=avg_salary\n",
    "job_details['Minimum salary']=min_salary\n",
    "job_details['Maximum salary']=max_salary\n",
    "job_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Csv file extraction\n",
    "job_details.to_csv(\"DataScientist_Noida_GlassDoor_Salary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to\n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoking chromedriver.exe file\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")\n",
    "#Opening the website\n",
    "URL = \"https://www.flipkart.com\"\n",
    "driver.get(URL)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching sunglasses and clicking the search button\n",
    "search_bar=driver.find_element_by_xpath(\"//input[@type='text']\")\n",
    "search_bar.send_keys('sunglasses')\n",
    "\n",
    "driver.find_element_by_xpath(\"//button[@type='submit']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "prod_desc=[]\n",
    "org_price=[]\n",
    "discount=[]\n",
    "disc_price=[]\n",
    "\n",
    "#We need to fetch for 100 listings \n",
    "#We will take a for loop and scrap data from all the pages\n",
    "for i in range(0,3):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        brand.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        prod_desc.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3I9_wc']\"):\n",
    "        org_price.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\"):\n",
    "        discount.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        disc_price.append(j.text)\n",
    "   \n",
    "    #Path for next page   \n",
    "    k=i+1\n",
    "    next_pg=\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\"+str(k)\n",
    "    driver.get(next_pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 119 119 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Original Price</th>\n",
       "      <th>Discounted Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹3,663</td>\n",
       "      <td>₹449</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹1,999</td>\n",
       "      <td>₹1,415</td>\n",
       "      <td>29% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹2,599</td>\n",
       "      <td>₹299</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹799</td>\n",
       "      <td>₹509</td>\n",
       "      <td>36% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>₹513</td>\n",
       "      <td>35% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹2,665</td>\n",
       "      <td>₹449</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Riding Glasses, UV Protection, Others Aviator ...</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>₹227</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fravy</td>\n",
       "      <td>UV Protection, Gradient, Night Vision Retro Sq...</td>\n",
       "      <td>₹1,999</td>\n",
       "      <td>₹339</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Av...</td>\n",
       "      <td>₹1,999</td>\n",
       "      <td>₹292</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹2,256</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description  \\\n",
       "0   ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...   \n",
       "1    VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...   \n",
       "2   kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...   \n",
       "3         Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...   \n",
       "4         Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "..             ...                                                ...   \n",
       "95  ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...   \n",
       "96    Singco India  Riding Glasses, UV Protection, Others Aviator ...   \n",
       "97           Fravy  UV Protection, Gradient, Night Vision Retro Sq...   \n",
       "98          GANSTA  UV Protection, Night Vision, Riding Glasses Av...   \n",
       "99  ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...   \n",
       "\n",
       "   Original Price Discounted Price Discount  \n",
       "0          ₹3,663             ₹449  87% off  \n",
       "1          ₹1,999           ₹1,415  29% off  \n",
       "2          ₹2,599             ₹299  88% off  \n",
       "3            ₹799             ₹509  36% off  \n",
       "4            ₹799             ₹513  35% off  \n",
       "..            ...              ...      ...  \n",
       "95         ₹2,665             ₹449  83% off  \n",
       "96         ₹1,499             ₹227  84% off  \n",
       "97         ₹1,999             ₹339  83% off  \n",
       "98         ₹1,999             ₹292  85% off  \n",
       "99         ₹2,256             ₹499  77% off  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the length of the data scraped\n",
    "print(len(brand),len(prod_desc),len(org_price),len(discount),len(disc_price))\n",
    "\n",
    "#Creating a new dataframe\n",
    "glass_details=pd.DataFrame({})\n",
    "glass_details['Brand']=brand[:100]\n",
    "glass_details['Description']=prod_desc[:100]\n",
    "glass_details['Original Price']=org_price[:100]\n",
    "glass_details['Discounted Price']=disc_price[:100]\n",
    "glass_details['Discount']=discount[:100]\n",
    "glass_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_details.to_csv(\"Glass_Details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to\n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoking chromedriver.exe file\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")\n",
    "#Opening the website\n",
    "URL = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(URL)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "review=[]\n",
    "full_summary=[]\n",
    "\n",
    "#As there are nearly 10 reviews per page, we will check for 11 pages and scrap the required data\n",
    "#Now we will take a for loop and scrap\n",
    "for i in range(0,11):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        Rating.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        review.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "        full_summary.append(j.text)\n",
    "        \n",
    "    #Path for next page as it changes for every page. We are appending numbers as pages change  \n",
    "    k=i+1\n",
    "    next_page=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(k) \n",
    "    driver.get(next_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 110 110\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(review),len(full_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Does the job</td>\n",
       "      <td>phone is good but in display is 720p lcd in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>I was using Iphone 6s and also Oneplus 6t. Bot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>It's a great phone. From camera to display eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating             Review  \\\n",
       "0       5          Brilliant   \n",
       "1       5   Perfect product!   \n",
       "2       5      Great product   \n",
       "3       5  Worth every penny   \n",
       "4       5          Fabulous!   \n",
       "..    ...                ...   \n",
       "95      4       Does the job   \n",
       "96      5          Wonderful   \n",
       "97      5        Pretty good   \n",
       "98      5             Super!   \n",
       "99      4             Super!   \n",
       "\n",
       "                                         Full summary  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  phone is good but in display is 720p lcd in th...  \n",
       "96  Nice value for money good and best price I pho...  \n",
       "97  I was using Iphone 6s and also Oneplus 6t. Bot...  \n",
       "98  It's a great phone. From camera to display eve...  \n",
       "99  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New dataframe\n",
    "phone_details=pd.DataFrame({})\n",
    "phone_details['Rating']=Rating[:100]\n",
    "phone_details['Review']=review[:100]\n",
    "phone_details['Full summary']=full_summary[:100]\n",
    "phone_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_details.to_csv(\"Phone_Details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and\n",
    "search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoking chromedriver.exe file\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")\n",
    "#Opening the website\n",
    "URL = \"https://www.flipkart.com\"\n",
    "driver.get(URL)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching sneakers in the search area\n",
    "search_bar=driver.find_element_by_xpath(\"//input[@type='text']\")\n",
    "search_bar.send_keys('sneakers')\n",
    "\n",
    "#clicking submit button\n",
    "driver.find_element_by_xpath(\"//button[@type='submit']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_desc=[]\n",
    "org_price=[]\n",
    "disct=[]\n",
    "disc_price=[]\n",
    "\n",
    "#We need to scrap for 100 products and here we will consider the data from first 4 pages\n",
    "#We will take a for loop and scrap data from all the pages\n",
    "for i in range(0,4):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        brand.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        product_desc.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3I9_wc']\"):\n",
    "        org_price.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\"):\n",
    "        disct.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        disc_price.append(j.text)\n",
    "   \n",
    "    #We are appending numbers as pages change  \n",
    "    k=i+1\n",
    "    next_page=\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\"+str(k)\n",
    "    driver.get(next_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 129 160 160 160\n"
     ]
    }
   ],
   "source": [
    "#Checking the length of the datas\n",
    "print(len(brand),len(product_desc),len(org_price),len(disct),len(disc_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Original Price</th>\n",
       "      <th>Discounted Price</th>\n",
       "      <th>Discount%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹1,996</td>\n",
       "      <td>₹748</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Shoes in Black Color Party wear/Outdoor/Casual...</td>\n",
       "      <td>₹999</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfiya</td>\n",
       "      <td>White Sneaker For Men's/Boy's Sneakers For Men</td>\n",
       "      <td>₹999</td>\n",
       "      <td>₹377</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shoes Bank</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹999</td>\n",
       "      <td>₹349</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PEHANOSA</td>\n",
       "      <td>Combo Pack Of 4 Casual Sneakers For Men</td>\n",
       "      <td>₹999</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>REEBOOT</td>\n",
       "      <td>Super &amp; Trendy Men's Pack of 02 Pair Shoes for...</td>\n",
       "      <td>₹999</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>JACK &amp; JONES</td>\n",
       "      <td>Smash v2 Sneakers For Men</td>\n",
       "      <td>₹4,499</td>\n",
       "      <td>₹1,958</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹3,499</td>\n",
       "      <td>₹1,406</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>CAMPUS</td>\n",
       "      <td>Firm IDP Sneakers For Men</td>\n",
       "      <td>₹1,899</td>\n",
       "      <td>₹1,329</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Englewood</td>\n",
       "      <td>Puma Smash v2 Buck Sneakers For Men</td>\n",
       "      <td>₹1,899</td>\n",
       "      <td>₹498</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                        Description  \\\n",
       "0       CALCADOS     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "1   Robbie jones  Shoes in Black Color Party wear/Outdoor/Casual...   \n",
       "2         Alfiya     White Sneaker For Men's/Boy's Sneakers For Men   \n",
       "3     Shoes Bank                                   Sneakers For Men   \n",
       "4       PEHANOSA            Combo Pack Of 4 Casual Sneakers For Men   \n",
       "..           ...                                                ...   \n",
       "95       REEBOOT  Super & Trendy Men's Pack of 02 Pair Shoes for...   \n",
       "96  JACK & JONES                          Smash v2 Sneakers For Men   \n",
       "97          FILA                          Sneakers Sneakers For Men   \n",
       "98        CAMPUS                          Firm IDP Sneakers For Men   \n",
       "99     Englewood                Puma Smash v2 Buck Sneakers For Men   \n",
       "\n",
       "   Original Price Discounted Price Discount%  \n",
       "0          ₹1,996             ₹748   62% off  \n",
       "1            ₹999             ₹379   62% off  \n",
       "2            ₹999             ₹377   62% off  \n",
       "3            ₹999             ₹349   65% off  \n",
       "4            ₹999             ₹499   50% off  \n",
       "..            ...              ...       ...  \n",
       "95           ₹999             ₹199   80% off  \n",
       "96         ₹4,499           ₹1,958   56% off  \n",
       "97         ₹3,499           ₹1,406   59% off  \n",
       "98         ₹1,899           ₹1,329   30% off  \n",
       "99         ₹1,899             ₹498   73% off  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new dataframe\n",
    "sneakers_details=pd.DataFrame({})\n",
    "sneakers_details['Brand']=brand[:100]\n",
    "sneakers_details['Description']=product_desc[:100]\n",
    "sneakers_details['Original Price']=org_price[:100]\n",
    "sneakers_details['Discounted Price']=disc_price[:100]\n",
    "sneakers_details['Discount%']=disct[:100]\n",
    "sneakers_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneakers_details.to_csv(\"Sneaker_Details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in\n",
    "the below image\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of\n",
    "the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "Please note that applying the filter and scraping the data , everything should be\n",
    "done through code only and there should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoking chromedriver.exe file\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")\n",
    "#Opening the website\n",
    "URL = \"https://www.myntra.com/shoes\"\n",
    "driver.get(URL)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the color black\n",
    "driver.find_element_by_xpath(\"//span[@data-colorhex='black']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the price range Rs. 6649 to Rs. 13099\n",
    "driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_page=0\n",
    "end_page=0\n",
    "\n",
    "for page in range(start_page,end_page+1): \n",
    "    nxt_button=driver.find_element_by_xpath(\"//li[@class='pagination-next']\")\n",
    "    \n",
    "    #Empty lists\n",
    "    shoe_names=[]\n",
    "    s_desc=[]\n",
    "    short_desc=[]\n",
    "    price=[]\n",
    "    \n",
    "    #Shoe brand names\n",
    "    Names=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")\n",
    "    for i in Names:\n",
    "        shoe_names.append(i.text)\n",
    "    \n",
    "    #Short-description\n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\")\n",
    "    for i in desc:\n",
    "        s_desc.append(i.text)\n",
    "    #As, the s_desc list contain blank description in every alternate index, so removing the blank or null description\n",
    "    for j in range(0,len(s_desc),2):\n",
    "        short_desc.append(s_desc[j])\n",
    "    \n",
    "    #Shoe prices\n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    for i in desc:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    #for scrapping the datas from next pages.\n",
    "    if nxt_button.text=='next':\n",
    "            nxt_button.click()\n",
    "            time.sleep(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "#Checking the length of the list\n",
    "print(len(shoe_names),len(short_desc),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand name</th>\n",
       "      <th>Short description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kalenji By Decathlon</td>\n",
       "      <td>Men KD500 Running Shoe</td>\n",
       "      <td>Rs. 7857Rs. 8449(7% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Air Max Siren Sneakers</td>\n",
       "      <td>Rs. 7375Rs. 8195(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Leather Derbys</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 6999Rs. 9999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Mirage Tech Sneakers</td>\n",
       "      <td>Rs. 7199Rs. 7999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Liberate Nitro Running</td>\n",
       "      <td>Rs. 7499Rs. 9999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Predator .3 FG Football Shoes</td>\n",
       "      <td>Rs. 6649Rs. 6999(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lacoste</td>\n",
       "      <td>Men Woven Design Sneakers</td>\n",
       "      <td>Rs. 8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Leather Slip-On Sneakers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Textured Oxfords</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Semiformal Driving</td>\n",
       "      <td>Rs. 10490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Solid REPOSTO Sneakers</td>\n",
       "      <td>Rs. 6795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Solid Leather Ballerinas</td>\n",
       "      <td>Rs. 9799Rs. 13999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>HOVR Sonic 3 Running Shoes</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Formal Leather Brogues</td>\n",
       "      <td>Rs. 7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Solid Leather Gladiators</td>\n",
       "      <td>Rs. 6993Rs. 9990(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women HOVR Apex 2 Training</td>\n",
       "      <td>Rs. 11899Rs. 13999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Leather Sneakers</td>\n",
       "      <td>Rs. 7699Rs. 10999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Women AIR ELEMENT 2 Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Provoke XT Training</td>\n",
       "      <td>Rs. 6649Rs. 6999(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged RC Sportstyle Sneakers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women SUPERNOVA Running Shoes</td>\n",
       "      <td>Rs. 9499Rs. 9999(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 7649Rs. 8499(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Reebok</td>\n",
       "      <td>Forever Floatride Energy 2</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Eternity Nitro Running</td>\n",
       "      <td>Rs. 9749Rs. 12999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Quechua By Decathlon</td>\n",
       "      <td>Men Trekking Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Nike</td>\n",
       "      <td>AIR ZOOM WINFLO Running Shoes</td>\n",
       "      <td>Rs. 7195Rs. 7995(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Running Shoes</td>\n",
       "      <td>Rs. 10795Rs. 11995(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Flex Advantage 4.0Upstream</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men Wingtip Oxford Sneakers</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men GENERATION ZEROGRAND STITCHLITE</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Football Shoes</td>\n",
       "      <td>Rs. 12749Rs. 16999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Liberate Nitro Running</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Slip-On Sneakers</td>\n",
       "      <td>Rs. 9490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men FUTURE Z 3.1Football Shoes</td>\n",
       "      <td>Rs. 7199Rs. 7999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RARE RABBIT</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Textured Leather Monks</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Sandals</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men 365 Evoknit Ignite Ct Football</td>\n",
       "      <td>Rs. 7499Rs. 9999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>VIONIC</td>\n",
       "      <td>Men Textured Sneakers</td>\n",
       "      <td>Rs. 7039Rs. 10999(36% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand name                    Short description  \\\n",
       "0   Kalenji By Decathlon               Men KD500 Running Shoe   \n",
       "1                   Nike         Women Air Max Siren Sneakers   \n",
       "2           Hush Puppies                   Men Leather Derbys   \n",
       "3                  ASICS                    Men Running Shoes   \n",
       "4                   Puma          Unisex Mirage Tech Sneakers   \n",
       "5                   Puma         Women Liberate Nitro Running   \n",
       "6                 ADIDAS        Predator .3 FG Football Shoes   \n",
       "7                   Geox            Men Leather Driving Shoes   \n",
       "8                Lacoste            Men Woven Design Sneakers   \n",
       "9           Hush Puppies         Men Leather Slip-On Sneakers   \n",
       "10             J.FONTINI         Men Textured Leather Loafers   \n",
       "11          Hush Puppies                 Men Textured Oxfords   \n",
       "12                  Geox       Men Leather Semiformal Driving   \n",
       "13          Hush Puppies      Men Solid Leather Formal Derbys   \n",
       "14          Hush Puppies    Men Solid Leather Formal Slip-Ons   \n",
       "15                  Nike         Women Solid REPOSTO Sneakers   \n",
       "16                  Puma                    Men Running Shoes   \n",
       "17             Cole Haan       Women Solid Leather Ballerinas   \n",
       "18          UNDER ARMOUR           HOVR Sonic 3 Running Shoes   \n",
       "19             J.FONTINI         Men Textured Leather Loafers   \n",
       "20                 Ruosh           Men Formal Leather Brogues   \n",
       "21               Bugatti      Men Solid Leather Formal Derbys   \n",
       "22          Hush Puppies    Men Solid Leather Formal Slip-Ons   \n",
       "23  Heel & Buckle London       Women Solid Leather Gladiators   \n",
       "24          UNDER ARMOUR           Women HOVR Apex 2 Training   \n",
       "25             Cole Haan               Women Leather Sneakers   \n",
       "26              Skechers         Women AIR ELEMENT 2 Sneakers   \n",
       "27                  Puma            Women Provoke XT Training   \n",
       "28          UNDER ARMOUR       Charged RC Sportstyle Sneakers   \n",
       "29                ADIDAS        Women SUPERNOVA Running Shoes   \n",
       "30                  FILA                    Men Running Shoes   \n",
       "31                Reebok           Forever Floatride Energy 2   \n",
       "32                  Puma         Women Eternity Nitro Running   \n",
       "33  Quechua By Decathlon                   Men Trekking Shoes   \n",
       "34                  Geox            Men Leather Driving Shoes   \n",
       "35                  Nike        AIR ZOOM WINFLO Running Shoes   \n",
       "36                  Nike                  Women Running Shoes   \n",
       "37              Skechers       Men Flex Advantage 4.0Upstream   \n",
       "38             Cole Haan          Men Wingtip Oxford Sneakers   \n",
       "39             Cole Haan  Men GENERATION ZEROGRAND STITCHLITE   \n",
       "40                  Puma                   Men Football Shoes   \n",
       "41                  Puma           Men Liberate Nitro Running   \n",
       "42                  Geox         Men Leather Slip-On Sneakers   \n",
       "43                  Puma       Men FUTURE Z 3.1Football Shoes   \n",
       "44           RARE RABBIT                  Men Leather Loafers   \n",
       "45                  FILA                 Men Leather Sneakers   \n",
       "46                 Ruosh           Men Textured Leather Monks   \n",
       "47                  ALDO                        Women Sandals   \n",
       "48                  Puma   Men 365 Evoknit Ignite Ct Football   \n",
       "49                VIONIC                Men Textured Sneakers   \n",
       "\n",
       "                          Price  \n",
       "0      Rs. 7857Rs. 8449(7% OFF)  \n",
       "1     Rs. 7375Rs. 8195(10% OFF)  \n",
       "2                      Rs. 7999  \n",
       "3     Rs. 6999Rs. 9999(30% OFF)  \n",
       "4     Rs. 7199Rs. 7999(10% OFF)  \n",
       "5     Rs. 7499Rs. 9999(25% OFF)  \n",
       "6      Rs. 6649Rs. 6999(5% OFF)  \n",
       "7                      Rs. 9990  \n",
       "8                      Rs. 8500  \n",
       "9                      Rs. 6999  \n",
       "10                     Rs. 6990  \n",
       "11                     Rs. 6999  \n",
       "12                    Rs. 10490  \n",
       "13                     Rs. 9999  \n",
       "14                     Rs. 8999  \n",
       "15                     Rs. 6795  \n",
       "16   Rs. 7799Rs. 12999(40% OFF)  \n",
       "17   Rs. 9799Rs. 13999(30% OFF)  \n",
       "18                    Rs. 10999  \n",
       "19                     Rs. 6990  \n",
       "20                     Rs. 7490  \n",
       "21                     Rs. 9999  \n",
       "22                     Rs. 8999  \n",
       "23    Rs. 6993Rs. 9990(30% OFF)  \n",
       "24  Rs. 11899Rs. 13999(15% OFF)  \n",
       "25   Rs. 7699Rs. 10999(30% OFF)  \n",
       "26                     Rs. 7999  \n",
       "27     Rs. 6649Rs. 6999(5% OFF)  \n",
       "28                     Rs. 8999  \n",
       "29     Rs. 9499Rs. 9999(5% OFF)  \n",
       "30    Rs. 7649Rs. 8499(10% OFF)  \n",
       "31                     Rs. 9999  \n",
       "32   Rs. 9749Rs. 12999(25% OFF)  \n",
       "33                     Rs. 9999  \n",
       "34                     Rs. 9999  \n",
       "35    Rs. 7195Rs. 7995(10% OFF)  \n",
       "36  Rs. 10795Rs. 11995(10% OFF)  \n",
       "37                     Rs. 6999  \n",
       "38                    Rs. 12999  \n",
       "39                    Rs. 11999  \n",
       "40  Rs. 12749Rs. 16999(25% OFF)  \n",
       "41                     Rs. 9999  \n",
       "42                     Rs. 9490  \n",
       "43    Rs. 7199Rs. 7999(10% OFF)  \n",
       "44                     Rs. 8499  \n",
       "45                     Rs. 7999  \n",
       "46                     Rs. 6990  \n",
       "47                     Rs. 8999  \n",
       "48    Rs. 7499Rs. 9999(25% OFF)  \n",
       "49   Rs. 7039Rs. 10999(36% OFF)  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new dataframe\n",
    "shoes_details=pd.DataFrame({})\n",
    "shoes_details['Brand name']=shoe_names\n",
    "shoes_details['Short description']=short_desc\n",
    "shoes_details['Price']=price\n",
    "shoes_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_details.to_csv(\"shoes_details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/\n",
    " Enter “Laptop” in the search field and then click the search icon.\n",
    " Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the\n",
    "below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes\n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoking chromedriver.exe file\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Admin\\Downloads\\chromedriver.exe\")\n",
    "#Opening the website\n",
    "URL = \"https://www.amazon.in\"\n",
    "driver.get(URL)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element_by_id('twotabsearchtextbox')\n",
    "search_bar.send_keys(\"laptop\")\n",
    "\n",
    "driver.find_element_by_id('nav-search-submit-button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering Intel Core i7 from filters\n",
    "filter1=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter1:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering Intel Core i9 from filters\n",
    "filter1=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter1:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As there are some data issue with no rating for many items, included this step\n",
    "ratingstar = driver.find_element_by_xpath(\"//*[@id='p_72/1318476031']/span/a/section/i\")\n",
    "ratingstar.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HP Pavilion (2021) Thin & Light 11th Gen Core i7 Laptop, 16 GB RAM, 1TB SSD, Iris Xe Graphics, 14\" (35.56cms) FHD Screen, Windows 10, MS Office, Backlit Keyboard (14-dv0058TU)',\n",
       " 'HP Pavilion Gaming 10th Gen Intel Core i7 Processor 15.6-inch FHD Gaming Laptop (16GB/512GB SSD + 32GB Intel Optane/Windows 10/NVIDIA 1650Ti 4GB/Shadow Black), 15-dk1509TX',\n",
       " 'Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.56cms) Full HD IPS 2-in-1 Touchscreen Laptop (16GB/512GB SSD/Windows 10/MS Office 2019/Fingerprint Reader/Slate Grey/Aluminium Surface/1.43Kg), 82BH004HIN',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i5-10210U 10th Gen 14-inch (35.56 cms) Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AR+Webcam',\n",
       " 'ASUS VivoBook S S14 Intel Core i7-1165G7 11th Gen 14-inch FHD Thin and Light Laptop (8GB RAM/512GB SSD + 32GB Optane Memory/Windows 10/Office 2019/Iris X Graphics ;Dreamy White;1.4 Kg), S433EA-AM702TS',\n",
       " 'Samsung Galaxy Book Flex 13.3” | Samsung Laptop with QLED Display and Intel Core i7 Processor | Galaxy Book Flex Laptop with Long Battery Life and Bluetooth-Enabled S Pen | (NP930QCG-K01US)',\n",
       " 'HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (11th Gen Intel i7-1165G7/8GB/512GB SSD/Windows 10/MS Office 2019/Alexa Built-in/Pale Gold/1.47 kg), 14s-dr2007TU',\n",
       " 'Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7 15.6-inch FHD IPS Gaming Laptop (8GB/1TB HDD + 256 GB SSD/Windows 10/NVIDIA GTX 1650 4GB GDDR6/with M100 RGB Gaming Mouse/Onyx Black/2.2Kg), 81Y400VAIN',\n",
       " 'Dell G3 3500 Gaming Laptop 15.6\" (39.62cms) FHD 120 Hz (10th Gen Core i7-10750H/8GB/512GB SSD/Windows 10 Home Plus & MS Office/NVIDIA1650 Ti Graphics/Eclipse Black) D560260WIN9BE',\n",
       " 'ASUS ZenBook 14 (2020) Intel Core i7-1065G7 10th Gen 14-inch FHD Thin and Light Laptop (16GB RAM/512GB NVMe SSD/Windows 10/MS Office 2019/Intel Iris Plus Graphics/Pine Grey/1.17 kg), UX425JA-BM701TS']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Titles\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "title=[]\n",
    "for i in titles[:10]:\n",
    "    title.append(i.text)\n",
    "\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping Price\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "price=[]\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['84,990',\n",
       " '86,990',\n",
       " '97,588',\n",
       " '54,999',\n",
       " '77,990',\n",
       " '88,990',\n",
       " '84,928',\n",
       " '90,150',\n",
       " '94,990',\n",
       " '1,20,990']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings=[]\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))\n",
    "for url in UR:\n",
    "    driver.get(url)\n",
    "    try:                  \n",
    "        rate=driver.find_element_by_xpath(\"//span[@id='acrCustomerReviewText']\")\n",
    "        rate.click()                                                      \n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "        Ratings.append(rating.text)#appending the ratings in Ratings list\n",
    "        \n",
    "    except NoSuchElementException as e:\n",
    "        Ratings.append(\"NO rating\")#appending the No rating if no rating is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "#checking the length of each list\n",
    "print(len(title),len(price),len(Ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>86,990</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>97,588</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>54,999</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>77,990</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsung Galaxy Book Flex 13.3” | Samsung Lapto...</td>\n",
       "      <td>88,990</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP 14 Thin &amp; Light 14\" (35.56cms) FHD Laptop (...</td>\n",
       "      <td>84,928</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...</td>\n",
       "      <td>90,150</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell G3 3500 Gaming Laptop 15.6\" (39.62cms) FH...</td>\n",
       "      <td>94,990</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1065G7 10...</td>\n",
       "      <td>1,20,990</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product name     Price        Rating\n",
       "0  HP Pavilion (2021) Thin & Light 11th Gen Core ...    84,990  4.5 out of 5\n",
       "1  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...    86,990  4.1 out of 5\n",
       "2  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...    97,588  4.3 out of 5\n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i5-1...    54,999  4.4 out of 5\n",
       "4  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...    77,990  4.4 out of 5\n",
       "5  Samsung Galaxy Book Flex 13.3” | Samsung Lapto...    88,990  4.6 out of 5\n",
       "6  HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (...    84,928  4.6 out of 5\n",
       "7  Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...    90,150  4.3 out of 5\n",
       "8  Dell G3 3500 Gaming Laptop 15.6\" (39.62cms) FH...    94,990  4.2 out of 5\n",
       "9  ASUS ZenBook 14 (2020) Intel Core i7-1065G7 10...  1,20,990  4.4 out of 5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new dataframe for saving the data\n",
    "amazon_details=pd.DataFrame({})\n",
    "amazon_details['Product name']=title\n",
    "amazon_details['Price']=price\n",
    "amazon_details['Rating']=Ratings\n",
    "amazon_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_details.to_csv(\"Laptop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-11216d855627>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-11216d855627>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pppppppppppppp//li[@class='fleft grey-text br2 placeHolderLi location']/span\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
